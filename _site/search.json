[
  {
    "objectID": "blog/posts/mlr3_basic/index.html",
    "href": "blog/posts/mlr3_basic/index.html",
    "title": "mlr3 기초",
    "section": "",
    "text": "Important\n\n\n\n이 글은 mlr3book1을 참고하여 작성되었습니다. 국내 R 사용자들에게 잘 알려지지 않은 mlr32 패키지를 통해, R에서도 손쉽게 머신러닝을 수행할 수 있다는 것을 보여드리고자 합니다."
  },
  {
    "objectID": "blog/posts/mlr3_basic/index.html#r6",
    "href": "blog/posts/mlr3_basic/index.html#r6",
    "title": "mlr3 기초",
    "section": "R6",
    "text": "R6\nR6는 객체지향 프로그래밍 (OOP)을 위한 R의 최근 패러다임 중 하나입니다. R6는 S3와 같이 R에 존재하던 기존의 객체지향성의 단점을 해결하는것이 특징입니다. 아마 다른 프로그래밍 언어에서 객체 지향 개념을 다루어 보셨다면, R6가 더 익숙하게 느껴질 것입니다.\nR6에서 객체(object)는 R6Class() 생성자 객체와 더불어 $new()메소드를 통해 생성됩니다.\n예를 들어 보겠습니다.\n\nlibrary(R6)\nFoo = R6Class()\nfoo = Foo$new()\n\n이 객체들은 자신들의 필드 안에서 변환 가능하도록 압축된 상태를 띄고 있는데, 우리는 이 객체들에 $ 기호를 통해 접근할 수 있습니다.\n필드 뿐만 아니라, 객체들이 갖고 있는 메소드를 통해 각 객체의 상태를 파악하고 정보를 검색하거나, 객체의 내부 상태를 변경할 수 있습니다. 예를 들어 mlr3 의 학습모델(learner) 의 $train() 메소드를 통해, 모델을 학습된 상태로 변경할 수 있고, 이를 통해 예측을 할 수 있게 됩니다.\n\n\n\n\n\n\nNote\n\n\n\nR6 객체의 내부 요소는 다음과 같이 부릅니다.\n\n$field: 필드, 정보\n$method(): 메소드, 특정 동작 실행\n\n\n\nR6 객체들은 각각의 환경(environment)로서, 참조 특성 (reference semantics)을 갖습니다. 예를 들어, foo2 = foo 를 실행할 시, foo2 는 foo가 복사된 것은 아니지만, 하나의 객체를 참조하고 있는 것입니다. 따라서, foo$bar = 3 을 실행할 시, foo2$bar 역시 3이 됩니다.\n객체를 복사할 경우 $clone() 메소드와 deep = TRUE 인자를 사용해야 합니다.\n\nfoo2 = foo$clone(deep=TRUE)\n\n\nlibrary(mlr3verse)\n\n\n\n\n\n\n\nTip\n\n\n\nR6에 대해 더 자세히 알고 싶다면, R6 vignettes, 특히 introduction부분을 참고하세요. 포괄적인 R6의 정보를 얻고 싶다면, Advanced R의 R6 챕터를 참고하세요.\n\n\n\n\nmlr3의 필수 활용요소\n\nSugar functions\n대부분의 mlr3 객체들은 sugar function으로 불리는 간편한 함수들을 제공합니다. 다시 말해, sugar function은 원래의 코드에 대한 단축키(shortcut)로서 사용자가 입력해야 하는 코드를 줄여줍니다. 예를 들어 lrn(\"regr.rpart\") 는 LearnerRegrRpart$new() 의 sugar 버전입니다.\n\n\nDictionaries\nmlr3는 러너(learners)나 태스크(tasks) 객체들을 저장하기 위해 dictionary 구조를 사용합니다. dictionary 구조는 key와 value로 이루어져 있어 key와 value를 연관시켜주는데, 이는 실제 사전의 단어와 단어의 설명과 같다고 이해하시면 됩니다.\ndictionary는 연관된 객체들을 묶어 나열하고 검색하기 쉽게 하기 위해 사용됩니다. 예를 들어 특정 학습모델을 검색할 때, mlr_learners dictionary에 원하는 러너(key)를 입력하면 검색이 가능합니다.\n예를 들면 다음과 같습니다.\n\nrequire(mlr3)\nmlr_learners$get('classif.rpart')\n\n<LearnerClassifRpart:classif.rpart>: Classification Tree\n* Model: -\n* Parameters: xval=0\n* Packages: mlr3, rpart\n* Predict Types:  [response], prob\n* Feature Types: logical, integer, numeric, factor, ordered\n* Properties: importance, missings, multiclass, selected_features,\n  twoclass, weights\n\n\n또한 as.data.table(mlr3_learners) 모든 학습 모델의 정보를 확인할 수도 있습니다.\n\n\nmlr3viz\nmlr3viz는 mlr3 생태계 안에서 시각화를 담당하는 패키지입니다. ggplot2의 theme_minimal()을 적용시킨 동일한 배경의 그래프들을 생성합니다. mlr3viz는 ggplot2 를 기반으로 하고 있으며, fortify와 autoplot 라는 확장 패키지를 통해 예측, 학습모델, 벤치마크 객체 등 mlr3의 결과물들을 시각화하는 데 사용됩니다. mlr3viz에서 가장 많이 사용되는 것은 autoplot()으로, 객체의 타입에 따라 그래프의 출력 결과가 결정됩니다."
  },
  {
    "objectID": "blog/posts/mlr3_basic/index.html#tasks",
    "href": "blog/posts/mlr3_basic/index.html#tasks",
    "title": "mlr3 기초",
    "section": "Tasks",
    "text": "Tasks\n태스크(task)은 데이터와 머신러닝 문제들을 정의한 메타데이터를 갖고 있는 객체입니다. 예를 들면 머신러닝의 분류에서 타겟 피처의 이름이 메타 데이터 입니다.\n한마디로, 태스크는 우리가 활용하는 기본 데이터와 머신러닝을 위해 필요한 데이터들을 담아둔 정보 등이 포함된 객체입니다.\n이 메타 데이터는 사용자가 모덜이 학습될 때 예측 타겟을 다시 지정해줄 필요 없도록 태스크와 함께 작동하게 됩니다.\n\n\n\n\n\n\nNote\n\n\n\nTask와 Learner 등 영어로 지정된 단어들은 따로 번역하지 않고, 소리 그대로 “태스크”와 “러너”로 부르겠습니다.\n\n\n\n내장 태스크\nmlr3에는 mlr_tasks라고 하는 R6 Dictionary 를 통해 미리 지정된 머신러닝 태스크를 제공하고 있습니다.\n\nmlr_tasks\n\n<DictionaryTask> with 19 stored values\nKeys: bike_sharing, boston_housing, breast_cancer, german_credit, ilpd,\n  iris, kc_housing, moneyball, mtcars, optdigits, penguins,\n  penguins_simple, pima, sonar, spam, titanic, usarrests, wine, zoo\n\n\nmlr_tasks에 내장된 태스크를 가져오기 위해선, tsk() 함수와 불러오고자 하는 태스크의 이름을 입력하면 됩니다.\n\ntask_mtcars <- tsk(\"mtcars\")\ntask_mtcars\n\n<TaskRegr:mtcars> (32 x 11): Motor Trends\n* Target: mpg\n* Properties: -\n* Features (10):\n  - dbl (10): am, carb, cyl, disp, drat, gear, hp, qsec, vs, wt\n\n\n특정 태스크에 대해 보다 많은 정보가 필요하다면, help()메소드를 이용하시면 됩니다.\n\ntask_mtcars$help()\n\n\n\n\n\n\n\nTip\n\n\n\nR을 사용하셨던 분들이라면 위와 같은 구조의 코드가 낯설 것입니다. 보통 도움말을 보기 위해선 help()나 ?를 이용했을테니까요.\ntask_mtcars$help() 와 같은 구조가 바로 R6 객체 구조입니다. Introduction에서 간단히 소개했었죠? 앞으로 mlr3를 배우며, 계속 사용하게 될 것입니다.\n\n\n\ntask_sonar <- tsk('sonar')\nsplit <- partition(task_sonar, ratio=.7)\n\n\n\n외부 데이터 태스크로 변환\nmlr3에서 제공하는 데이터가 아닌, 외부의 데이터셋을 mlr3 패키지와 사용하려면 아래와 같이 데이터셋을 태스크로 변환해야 합니다. 예를 들어, survival 패키지의 lung 데이터셋을 mlr3의 태스크 객체로 변환한다면, 아래와 같이 진행할 수 있습니다.\n\nlibrary(survival)\nlibrary(data.table)\ntask_lung = as_task_classif(\n  as.data.table(lung)[,.(age, sex, wt.loss, ph.ecog,status)],\n             target = \"status\",\n  \n             id = \"lung\")\ntask_lung\n\n<TaskClassif:lung> (228 x 5)\n* Target: status\n* Properties: twoclass\n* Features (4):\n  - dbl (4): age, ph.ecog, sex, wt.loss\n\n\n\n\n\n\n\n\nTip\n\n\n\n태스크 생성자인 as_task_regr()과 as_task_classif()는 각각 머신러닝의 회귀와 분류를 수행하기 위한 태스크를 만드는 함수입니다.\n외부의 데이터를 태스크로 변환할 때, UTF8 이름을 따르지 않는 경우, 머신러닝 학습과정에서 오류가 발생합니다. 예를 들면,\nTask 'lung' has missing values in column(s) 'ph.ecog', 'wt.loss', but learner 'classif.ranger' does not support this\n따라서 make.names() 함수를 이용해 데이터의 열 이름을 변경하는 것을 권장합니다.\n\n\n\nlibrary(mlr3viz)\nautoplot(task_lung, type = \"pairs\")\n\n\n\n\n\n\n데이터 살펴보기\n태스크 객체는 테이블 형태의 데이터와 함께, 메타 데이터를 포함하고 있습니다. 예를 들면 행과 열의 개수, 피처(feature) 변수, 타겟 변수와 각 변수의 데이터유형 등을 확인할 수 있습니다.\n이런 메타 데이터들은 field를 통해 확인이 가능합니다.\n\ntask_lung$nrow\n\n[1] 228\n\n\n\ntask_lung$ncol\n\n[1] 5\n\n\n피처와 타겟변수의 이름은 각각 $feature_names 와 $target_names 에 저장되어 있습니다. 여기서 target 은 머신러닝을 통해 예측하고자 하는 변수를 의미합니다.\n\ntask_lung$feature_names\n\n[1] \"age\"     \"ph.ecog\" \"sex\"     \"wt.loss\"\n\n\n\ntask_lung$target_names\n\n[1] \"status\"\n\n\n한편 태스크 안에 들어있는 데이터는 data.table 객체로, $data() 메소드를 통해 확인할 수 있습니다.\n\ntask_lung$data()\n\n\n\n  \n\n\n\n$data() 메소드 안에서 rows와 cols를 통해 원하는 데이터를 확인할 수 있습니다.\n\ntask_lung$data(rows=1:10, cols=\"status\")\n\n\n\n  \n\n\n\n태스크를 data.table 객체로 바꾼다면, 데이터에 있는 모든 변수를 확인할 수도 있습니다.\n\nsummary(as.data.table(task_lung))\n\n status       age           ph.ecog            sex           wt.loss       \n 1: 63   Min.   :39.00   Min.   :0.0000   Min.   :1.000   Min.   :-24.000  \n 2:165   1st Qu.:56.00   1st Qu.:0.0000   1st Qu.:1.000   1st Qu.:  0.000  \n         Median :63.00   Median :1.0000   Median :1.000   Median :  7.000  \n         Mean   :62.45   Mean   :0.9515   Mean   :1.395   Mean   :  9.832  \n         3rd Qu.:69.00   3rd Qu.:1.0000   3rd Qu.:2.000   3rd Qu.: 15.750  \n         Max.   :82.00   Max.   :3.0000   Max.   :2.000   Max.   : 68.000  \n                         NA's   :1                        NA's   :14       \n\n\n\n\n태스크 변환자(Mutators)\n머신러닝을 수행하며, 행과 열들을 선택하는 경우가 종종 있습니다. 예를 들면 train-test split을 위해 행을 선택하는 경우, 모델링에 넣을 피처들을 선택하는 경우가 있겠죠.\nmlr3의 태스크는 행을 선택하는 $filter(), 열을 선택하는 $select() 를 이용해 원하는 조건의 데이터를 추출할 수 있습니다.\n한 가지 주의해야 할 것이 있습니다. $select()와 $filter()는 변환자이기 때문에, 기존의 태스크를 수정하게 됩니다. 다시 말해, 처음에 있던 원래 데이터를 바꿔버리는 것이죠.\n\ntask_iris <- tsk(\"iris\")\ntask_iris$select(c(\"Sepal.Length\",\"Petal.Width\"))\ntask_iris$filter(2:4)\ntask_iris$data()\n\n\n\n  \n\n\n\n이를 방지하기 위해서는 $clone() 메소드를 이용해 새로운 태스크로 복사한 뒤에 행이나 열을 선택하는 작업하시면 됩니다.\n\ntask_iris_copy <- task_iris$clone()\ntask_iris_copy$filter(2)\ntask_iris_copy$data()\n\n\n\n  \n\n\n\n\ntask_iris$data()\n\n\n\n  \n\n\n\ntask_iris_copy는 task_iris를 복사한 뒤, 2번째 행을 $filter() 했지만, task_iris의 데이터는 아무 변화가 없는 것을 확인할 수 있습니다."
  },
  {
    "objectID": "blog/posts/mlr3_basic/index.html#learner",
    "href": "blog/posts/mlr3_basic/index.html#learner",
    "title": "mlr3 기초",
    "section": "Learner",
    "text": "Learner\n러너는 클래스는 널리 알려진 많은 머신러닝 패키지들을 통일된 형태로 제공합니다. 태스크와 마찬가지로 mlr_learners dictionary를 통해 확인할 수 있습니다.\n러너는 머신러닝 모델을 학습(train)하고 예측하는 역할을 수행합니다. 태스크에서는 외부 데이터도 태스크로 만들 수 있었던 것과 달리, 러너는 mlr3에서 지원하는 것만 사용할 수 있습니다. mlr3에서 제공하는 러너들은 다음과 같습니다.\n\nas.data.table(mlr_learners) |> head()\n\n\n\n  \n\n\n\n러너의 기본 형태는 Learner입니다. Learner로 시작하는 다양한 러너들이 존재합니다. mlr3의 러너들은 mlr3learners와 mlr3extralearners패키지를 통해 확인 가능합니다.\n\nmlr3learners::LearnerClassifLogReg\n\n<LearnerClassifLogReg> object generator\n  Inherits from: <LearnerClassif>\n  Public:\n    initialize: function () \n    loglik: function () \n    clone: function (deep = FALSE) \n  Private:\n    .train: function (task) \n    .predict: function (task) \n  Parent env: <environment: namespace:mlr3learners>\n  Locked objects: TRUE\n  Locked class: FALSE\n  Portable: TRUE\n\n\n러너의 sugar function은 lrn() 입니다.\n\n\n\n\n\n\nDanger\n\n\n\nmlr3의 러너를 실행하기 위한 패키지가 없다면 아래와 같은 경고 메시지가 뜹니다.\nWarning: Package 'ranger' required but not installed for Learner 'classif.ranger\n패키지를 설치해주시면 간단히 해결됩니다.\n\ninstall.packages(\"ranger\")\n\n\n\n\nlearner_rf <- lrn('classif.ranger', predict_type='prob')\nlearner_rf\n\n<LearnerClassifRanger:classif.ranger>\n* Model: -\n* Parameters: num.threads=1\n* Packages: mlr3, mlr3learners, ranger\n* Predict Types:  response, [prob]\n* Feature Types: logical, integer, numeric, character, factor, ordered\n* Properties: hotstart_backward, importance, multiclass, oob_error,\n  twoclass, weights\n\n\n각 러너들은 아래의 메타데이터를 갖고 있습니다.\n\n$feature_types: 피처들의 유형\n$packages: 모델을 학습시키고 예측하기 위해 필요한 패키지들\n$properties: 해당 러너가 갖고 있는 추가적인 특성. 예를 들어 importance 특성이 있다면 학습 후, 각 피처들의 importance를 추출할 수 있습니다.\n$predict_types: 해당 러너를 활용해 가능한 예측 유형입니다. 분류 유형의 러너는 response와 prob을 출력합니다.\n\n모든 러너들은 두 단계에 걸쳐 진행됩니다.\n\n학습 (Training): $train() 메소드를 통해 학습시키고자 하는 태스크를 전달합니다.\n예측 (Prediction): $predict() 메소드에 학습 때 사용하지 않은 데이터를 사용합니다. 학습 데이터를 기반으로 훈련된 모델이 새로운 데이터를 받아 예측값을 반환합니다.\n\n\n\n\n\n\n\nWarning\n\n\n\n러너가 학습되지 않았다면 $predict() 실행 시 에러가 발생합니다.\n\n\n\ntrain: 학습시키기\n앞서 말했듯이, mlr3에서는 러너에 태스크를 투입하여 모델을 학습시킵니다. 머신러닝에서는 태스크를 투입하기 전, 훈련에 사용할 데이터와 예측에 사용할 데이터를 나누는 것이 일반적입니다.\nmlr3 에서는 $partition() 메소드를 이용해 두 개의 데이터로 나눌 수 있습니다. 기본값은 전체 데이터의 67%를 훈련에, 나머지 33%를 예측에 사용합니다. 물론 이 비율은 ratio 인자 (범위: 0~1)를 통해 변경 가능합니다.\n\ntask_breast <- tsk(\"breast_cancer\")\nsplits <- partition(task_breast, ratio = 0.7)\n\n데이터를 나눠줬으니, 이제 모델을 학습시켜보도록 하겠습니다. 위에서 선언한 랜덤포레스트 러너에서 $train() 메소드를 실행시킵니다. 태스크와 row_ids에는 split 중 train에 해당하는 부분을 입력합니다.\n\nlearner_rf$train(task_breast, \n                 row_ids = split$train)\nlearner_rf$model\n\nRanger result\n\nCall:\n ranger::ranger(dependent.variable.name = task$target_names, data = task$data(),      probability = self$predict_type == \"prob\", case.weights = task$weights$weight,      num.threads = 1L) \n\nType:                             Probability estimation \nNumber of trees:                  500 \nSample size:                      146 \nNumber of independent variables:  9 \nMtry:                             3 \nTarget node size:                 10 \nVariable importance mode:         none \nSplitrule:                        gini \nOOB prediction error (Brier s.):  0.03533266 \n\n\n학습을 시킨 이후, $model 필드를 통해 학습된 결과를 확인할 수 있습니다. 어떤 하이퍼파라미터가 사용되었는지 등의 정보를 확인할 수 있습니다.\n각 러너들은 하이퍼파라미터들을 조정해줄 수 있습니다. 러너들의 파라미터를 확인하는 명령어는 다음과 같습니다.\n\nlearner_rf$param_set\n\n\n\n\n\n  \n\n\n\n현재 학습에 사용된 하이퍼 파라미터들은 values 필드에 저장되어있습니다.\n\nlearner_rf$param_set$values\n\n$num.threads\n[1] 1\n\n\n위와 같이 하이퍼 파라미터에 접근한 뒤, 기존의 값을 원하는 값으로 변경하거나, 새로운 하이퍼파라미터에 값을 설정해줄 수 있습니다.\n\nlearner_rf$param_set$values$num.threads = 10\nlearner_rf$param_set$values$num.trees = 20\nlearner_rf$param_set$values\n\n$num.threads\n[1] 10\n\n$num.trees\n[1] 20\n\n\n또는 lrn() 함수로 러너를 생성할 때, 원하는 하이퍼파라미터를 설정해줄 수 있습니다.\n\nlearner_rf <- lrn('classif.ranger', num.trees= 30)\nlearner_rf$param_set$values\n\n$num.threads\n[1] 1\n\n$num.trees\n[1] 30\n\n\n\nlearner_rf$train(task_breast, row_ids = split$train)\nlearner_rf\n\n<LearnerClassifRanger:classif.ranger>\n* Model: ranger\n* Parameters: num.threads=1, num.trees=30\n* Packages: mlr3, mlr3learners, ranger\n* Predict Types:  [response], prob\n* Feature Types: logical, integer, numeric, character, factor, ordered\n* Properties: hotstart_backward, importance, multiclass, oob_error,\n  twoclass, weights\n\n\n변경된 파라미터가 적용된 것을 확인할 수 있습니다.\n\n\n\n\n\n\nNote\n\n\n\n하이퍼 파라미터에 대한 자세한 설명은 하이퍼파라미터 튜닝에서 더 자세히 다루도록 하겠습니다.\n\n\n\n\npredict: 예측하기\n모델 학습이 완료되었다면, 예측값을 만들어볼 수 있습니다. split의 test 를 이용해 $predict() 메소드를 실행합니다.\n\nprediction <- learner_rf$predict(task_breast, \n                                 row_ids = split$test)\nprediction\n\n<PredictionClassif> for 62 observations:\n    row_ids     truth  response\n          3    benign    benign\n          6 malignant malignant\n          9    benign    benign\n---                            \n        204    benign    benign\n        206 malignant malignant\n        207    benign    benign\n\n\n예측값을 살펴보니, 예측값이 범주로 나타났습니다. 만약 범주에 대한 예측 확률값을 구하고 싶을 경우, lrn()의 predict_type을 prob으로 조정해주면 됩니다.\n\nlearner_rf <- lrn(\"classif.ranger\", \n                  predict_type=\"prob\")\nlearner_rf$train(task_breast, \n                 row_ids = split$train)\nprediction <- learner_rf$predict(task_breast, \n                                 row_ids = split$test)\nprediction\n\n<PredictionClassif> for 62 observations:\n    row_ids     truth  response prob.malignant prob.benign\n          3    benign    benign    0.000000000  1.00000000\n          6 malignant malignant    0.994350000  0.00565000\n          9    benign    benign    0.044171429  0.95582857\n---                                                       \n        204    benign    benign    0.002421429  0.99757857\n        206 malignant malignant    0.945166667  0.05483333\n        207    benign    benign    0.000000000  1.00000000\n\n\nprediction 객체에서는 $confusion 을 이용해 confusion matrix를 확인할 수 있습니다.\n\nprediction$confusion\n\n           truth\nresponse    malignant benign\n  malignant        27      0\n  benign            0     35\n\n\n우리가 만든 모델이 내놓은 예측값에 대한 시각화를 진행해줄 수 있습니다. mlr3viz 패키지의 autoplot() 기능을 이용해주면 됩니다.\nautoplot()에서 type을 어떻게 지정해주는지에 따라 예측값에 시각화가 다르게 나타납니다.\n\nlibrary(mlr3viz)\nautoplot(prediction)\n\n\n\n\n위의 그림은 test 데이터의 실제 target 값과 머신러닝 모델이 예측한 target을 비교한 값입니다.\n그 외에도 분류 계열의 모델에는 AUROC(type=\"roc\" )와 AUPRC(type=\"prc\") 등을 시각화할 수 있습니다.\n\n# install.packages(\"precrec\")\nautoplot(prediction, type=\"roc\")\nautoplot(prediction, type=\"prc\")\n\n\n\n\n\n\nAUROC\n\n\n\n\n \n\n\n\n\n\nAUPRC\n\n\n\n\n\n\n\n\nEvaluation: 성능 평가\n성능 평가는 머신러닝 모델링 과정에서 중요한 단계입니다. 앞서 예측 부분에서 예측값을 시각화로 표현했습니다. 그와 더불에 mlr3에서는 msr() 함수를 이용해 다양한 성능 지표들을 계산하고 비교할 수 있습니다. mlr_measures 딕셔너리를 보면 계산 가능한 지표들이 나와있습니다.\n예를 들어, 분류(classification) 모델에 대한 지표들을 살펴보면 다음과 같습니다.\n\nmlr_measures$keys(\"classif\")\n\n [1] \"classif.acc\"         \"classif.auc\"         \"classif.bacc\"       \n [4] \"classif.bbrier\"      \"classif.ce\"          \"classif.costs\"      \n [7] \"classif.dor\"         \"classif.fbeta\"       \"classif.fdr\"        \n[10] \"classif.fn\"          \"classif.fnr\"         \"classif.fomr\"       \n[13] \"classif.fp\"          \"classif.fpr\"         \"classif.logloss\"    \n[16] \"classif.mauc_au1p\"   \"classif.mauc_au1u\"   \"classif.mauc_aunp\"  \n[19] \"classif.mauc_aunu\"   \"classif.mbrier\"      \"classif.mcc\"        \n[22] \"classif.npv\"         \"classif.ppv\"         \"classif.prauc\"      \n[25] \"classif.precision\"   \"classif.recall\"      \"classif.sensitivity\"\n[28] \"classif.specificity\" \"classif.tn\"          \"classif.tnr\"        \n[31] \"classif.tp\"          \"classif.tpr\"        \n\n\n모델의 성능을 계산하기 위한 지표는 한 가지만 사용할 수 있고, 여러 가지를 사용할수도 있습니다.\n\nmeasure <- msr(\"classif.auc\")\nmeasures <- msrs(c(\"classif.auc\",\"classif.auc\"))\n\n모든 성능 지표들은 예측값과 test 데이터의 실제 값의 차이를 통해 수치화된 값입니다. 이 말은 모델의 성능을 평가하기 위해선, 예측값을 비교하기 위한, 모델 학습에 사용되지 않은 실제값이 필요하다는 것입니다.\n이제, Measure 객체 중 하나인 classif.acc를 통해 위에서 만든 랜덤포레스트 모델의 성능을 평가해보도록 하겠습니다. 지표(measure)를 생성한 뒤, 모델의 예측값 객체(prediction)의 $score() 메소드에 넘겨주면 해당 지표의 성능이 평가됩니다.\n\nmeasure <- msr(\"classif.acc\")\nmeasure\n\n<MeasureClassifSimple:classif.acc>: Classification Accuracy\n* Packages: mlr3, mlr3measures\n* Range: [0, 1]\n* Minimize: FALSE\n* Average: macro\n* Parameters: list()\n* Properties: -\n* Predict type: response\n\n\n\nprediction$score(measure)\n\nclassif.acc \n          1 \n\n\n\n\n\n\n\n\nNote\n\n\n\n$score()는 measure 없이 사용될 수 있습니다. 이럴 경우, 분류의 경우 기본값인 분류오차(classif.ce)가, 회귀는 평균제곱오차(regr.mse)가 적용됩니다.\n\n\n$score()를 이용해 여러 종류의 성능 지표를 한 번에 계산하는 것도 가능합니다. 예를 들어, 민감도(classif.sensitivity)와 특이도(classif.specificity)를 한번에 계산할 경우,\n\nmeasures <- msrs(c(\"classif.sensitivity\",\"classif.specificity\"))\n\nprediction$score(measures)\n\nclassif.sensitivity classif.specificity \n                  1                   1 \n\n\n뿐만 아니라, mlr3에서는 예측 모델의 품질을 정량화하는 지표로도 모델을 평가할 수 있습니다. 예를 들어, 학습하는 시간과 예측하는 시간을 평가하기 위해선\n\nmeasures <- msrs(c(\"time_train\", \"time_predict\"))\nprediction$score(measures,learner = learner_rf)\n\n  time_train time_predict \n        0.03         0.02 \n\n\n참고로, 위처럼 학습시간과 예측 시간을 평가하기 위해선 학습된 러너를 $score()에 입력해주어야 합니다.\n한편, 일부 지표들은 스스로 하이퍼파라미터를 가지고 있습니다. 대표적인 예로 selected_features 지표가 있습니다. 이 지표는 “selected_features” 속성이 있는 러너에만 사용 가능한 지표로서, 모델이 학습 시 사용한 피처에 대한 정보를 제공해줍니다. 이런 지표의 경우, $score() 에 태스크와 러너를 추가로 입력해주어야 합니다.\n\ntask_boston <- tsk(\"boston_housing\")\nsplits <- partition(task_boston)\nlearner_rpart <- lrn(\"regr.rpart\")\n\nlearner_rpart$train(task_boston, splits$train)\nprediction <- learner_rpart$predict(task_boston, splits$test)\nmeasure <- msr(\"selected_features\")\nprediction$score(measure, task = task_boston, learner = learner_rpart)\n\nselected_features \n                1 \n\n\nselected_features 는 선택된 피처의 수를 정규화해줄 수 있는 하이퍼파라미터를 설정할 수 있습니다.\n\nmeasure <- msr(\"selected_features\", normalize=T)\nprediction$score(measure, task=task_boston, learner = learner_rpart)\n\nselected_features \n       0.05555556"
  },
  {
    "objectID": "blog/posts/mlr3_basic/index.html#레퍼런스",
    "href": "blog/posts/mlr3_basic/index.html#레퍼런스",
    "title": "mlr3 기초",
    "section": "레퍼런스",
    "text": "레퍼런스\n\nhttps://mlr3.mlr-org.com/\nhttps://mlr3book.mlr-org.com/basics.html"
  },
  {
    "objectID": "blog/posts/mlr3_hyperparameter/index.html",
    "href": "blog/posts/mlr3_hyperparameter/index.html",
    "title": "mlr3 하이퍼파라미터 최적화",
    "section": "",
    "text": "Important\n\n\n\n이 글은 mlr3book1을 참고하여 작성되었습니다. 국내 R 사용자들에게 잘 알려지지 않은 mlr32 패키지를 통해, R에서도 손쉽게 머신러닝을 수행할 수 있다는 것을 보여드리고자 합니다.\n머신러닝 알고리즘은 보통 파라미터와 하이퍼파라미터를 포함하고 있습니다. 파라미터란 모델의 회귀계수나 가중치처럼 모델을 만들 때 필요한 매개변수입니다. 반면, 하이퍼파라미터는 사용자에 의해 구성됨으로써 파라미터가 어떻게 나올지를 결정합니다.\n대표적인 하이퍼파라미터의 예시로는 랜덤포레스트 알고리즘에서 나무의 개수를 정한다던가, 신경망의 학습률을 조정하는 것 등이 있습니다.\n하이퍼파라미터는 어떻게 설정하는지에 따라 모델의 성능을 향상시킬 수도, 그 반대가 될 수도 있습니다. 따라서 하이퍼파라미터를 최적화함으로써, 주어진 태스크에 대해 최적의 알고리즘 모델을 개발하는 것이 필요합니다.\n어쩌면 최적의 모델을 구성하는 것이 하나의 러너에 하이퍼 파라미터를 다르게 부여하는 벤치마크 실험을 통해 모델을 선택하는 것과 같다고 생각할 수 있습니다. 예를 들어 랜덤포레스트 모델들을 구성하는 나무의 개수를 다르게 정의하여 성능을 비교해본다고 해봅시다.\n결과를 봤을 때, 나무가 100개로 구성된 랜덤포레스트 모델의 성능이 가장 좋은 것으로 나타났습니다. 다만 이렇게 임의적으로 시행착오를 거쳐 하이퍼파라미터를 조정해주는 것은 많은 시간이 필요한 것은 물론, 종종 편향되고 재생산성이 떨어집니다.\n지금까지 개발되어온 정교한 하이퍼파라미터 최적화 방법은 종료(termination) 시점까지 반복적으로 다양한 파라미터를 검토 후, 최적의 하이퍼파라미터 구성을 내놓는 효율적이고 로버스트한 결과를 출력합니다."
  },
  {
    "objectID": "blog/posts/mlr3_hyperparameter/index.html#러너의-학습공간-설정",
    "href": "blog/posts/mlr3_hyperparameter/index.html#러너의-학습공간-설정",
    "title": "mlr3 하이퍼파라미터 최적화",
    "section": "러너의 학습공간 설정",
    "text": "러너의 학습공간 설정\n각각의 러너들은 하이퍼파라미터 세트를 갖고 있습니다.\n\nlrn_svm <- lrn(\"classif.svm\")\nlrn_svm$param_set\n\n<ParamSet>\nKey: <id>\n                 id    class lower upper nlevels\n             <char>   <char> <num> <num>   <num>\n 1:       cachesize ParamDbl  -Inf   Inf     Inf\n 2:   class.weights ParamUty    NA    NA     Inf\n 3:           coef0 ParamDbl  -Inf   Inf     Inf\n 4:            cost ParamDbl     0   Inf     Inf\n 5:           cross ParamInt     0   Inf     Inf\n 6: decision.values ParamLgl    NA    NA       2\n 7:          degree ParamInt     1   Inf     Inf\n 8:         epsilon ParamDbl     0   Inf     Inf\n 9:          fitted ParamLgl    NA    NA       2\n10:           gamma ParamDbl     0   Inf     Inf\n11:          kernel ParamFct    NA    NA       4\n12:              nu ParamDbl  -Inf   Inf     Inf\n13:           scale ParamUty    NA    NA     Inf\n14:       shrinking ParamLgl    NA    NA       2\n15:       tolerance ParamDbl     0   Inf     Inf\n16:            type ParamFct    NA    NA       2\n                                                                                      default\n                                                                                       <list>\n 1:                                                                                        40\n 2:                                                                                          \n 3:                                                                                         0\n 4:                                                                                         1\n 5:                                                                                         0\n 6:                                                                                     FALSE\n 7:                                                                                         3\n 8:                                                                                       0.1\n 9:                                                                                      TRUE\n10: <NoDefault>\\n  Public:\\n    clone: function (deep = FALSE) \\n    initialize: function () \n11:                                                                                    radial\n12:                                                                                       0.5\n13:                                                                                      TRUE\n14:                                                                                      TRUE\n15:                                                                                     0.001\n16:                                                                          C-classification\n    parents  value\n     <list> <list>\n 1:               \n 2:               \n 3:  kernel       \n 4:    type       \n 5:               \n 6:               \n 7:  kernel       \n 8:               \n 9:               \n10:  kernel       \n11:               \n12:    type       \n13:               \n14:               \n15:               \n16:"
  },
  {
    "objectID": "blog/posts/mlr3_hyperparameter/index.html#sec-hyperparameter",
    "href": "blog/posts/mlr3_hyperparameter/index.html#sec-hyperparameter",
    "title": "mlr3 하이퍼파라미터 최적화",
    "section": "Hyperparameter tuning",
    "text": "Hyperparameter tuning\n\nlrn_rf$param_set\nrequire(paradox)\nlrn_rf <- lrn('classif.ranger',\n              max.depth=to_tune(10,50),\n              mtry = to_tune(5,20),\n              num.trees = to_tune(30,100)\n              )\n\n# ti: TuningInstance\ninstance <- ti(\n  task = task_sonar,\n  learner = lrn_rf,\n  resampling = rsmp('cv',folds=5),\n  measures = msrs(c('classif.sensitivity',\n                    'classif.specificity')),\n  terminator = trm('evals',n_evals=100)\n)\ninstance\ntuner = tnr('random_search')\n\ntuner$optimize(instance)\n\n\nlrn_rf$param_set$values <-  instance$result_learner_param_vals[[1]]\n\nlrn_rf\n\n\nAutoTuner\n\nlrn_xgb <- lrn('classif.xgboost',\n               eta = to_tune(1e-4,1e-2),\n               gamma=to_tune(1e-3,1e-2),\n               max_depth=to_tune(10,50),\n               predict_type='prob'\n               )\n\nat <- auto_tuner(\n  method=tnr('random_search'),\n  learner = lrn_xgb,\n  resampling = rsmp('cv',folds=5),\n  measure = msr('classif.auc'),\n  term_evals = 30\n)\n\nat$train(task_sonar)\n\n\n\nNested Resampling\n\nouter_resampling <- rsmp('cv',folds=3)\n\nrr <- resample(task_sonar, at, outer_resampling, store_models = T)\n\nextract_inner_tuning_results(rr)\nrr$score(measures)\nrr$aggregate(measures)"
  },
  {
    "objectID": "blog/posts/mlr3_hyperparameter/index.html#feature-selection",
    "href": "blog/posts/mlr3_hyperparameter/index.html#feature-selection",
    "title": "mlr3 하이퍼파라미터 최적화",
    "section": "5. Feature selection",
    "text": "5. Feature selection\n\n5.1. Introduction\nfeature selection의 장점\n\n과적합(overfitting) 감소로 인한 성능 향상\n불필요한 feature에 의존하지 않는 안정된(robust) 모델\n간단함으로 인한 해석의 용이함\n잠재적으로 값비싼 feature 수집 불필요\n\n\n\n5.2. Filters\n\n5.2.1 Filter value 계산\nmlr3filters::mlr_filters dictionary 통해 또는 mlr3filters::flt() 를 이용해 filter 선택 가능.\nFilter 클래스에는 $calculate() 메소드가 존재하는데, filter value와 등수를 내림차순 정렬하여 보여준다.\n예를 들어 information gain filter를 이용하는 경우,\n\nlibrary(mlr3verse)\nfilter <- flt('information_gain')\ntask <- tsk('penguins')\ntask\nfilter$calculate(task)\nfilter\n\n일부 filter들은 hyperparameters가 존재하는데, learner에서 param_set을 변경해주는 것처럼 간단히 변경 가능합니다.\n\nfilter_cor <- flt('correlation')\nfilter_cor$param_set$values <- list(method='spearman')\nfilter_cor$param_set\n\n\n\n5.2.2. Feature importance filters\nimportance 가 있는 모든 모델에서 사용 가능한 filter입니다. ranger와 같은 일부 learner에서는 learner를 만들 때 지정을 해줘야 합니다.\n\nlrn_rf <- lrn('classif.ranger', importance='impurity')\n\n# remove missing values\ntask$filter(which(complete.cases(task$data())))\n\nfilter_imp <- flt('importance', learner=lrn_rf)\nfilter_imp$calculate(task)\nfilter_imp\n\n\n\n5.2.3. Embedded methods\nEmbedded methods는 Learner들로 하여금 예측에 중요한 변수들을 선택하는 방법입니다. 많은 learner들이 이 기능을 갖고 있습니다.\n\ntask <- tsk('penguins')\nlearner <- lrn('classif.rpart')\n\nstopifnot('selected_features' %in% learner$properties)\n\nlearner$train(task)\nlearner$selected_features()\n\nfilter <- flt('selected_features', learner=learner)\nfilter$calculate(task)\nfilter\n\nmodel에 의해 선택된 feature의 점수만 1, 나머지는 0 (dropped features)\n\n\n5.2.4. Filter-based feature selection\nfilter를 통해 각 feature들의 점수가 계산이 되었다면, 다음 모델링 단계에서 feature를 선택하여 학습을 시켜주어야 합니다.\n\ntask <- tsk('penguins')\nlearner <- lrn('classif.rpart')\nfilter <- flt('selected_features', learner=learner)\nfilter$calculate(task)\n\nkeep <- names(which(filter$scores==1))\ntask$select(keep) # column을 선택하기 때문에 select\ntask$feature_names\n\n위의 예시에서는 selected_features를 했기 때문에 0과 1로 구분이 되었지만, 연속형 점수에 대해 filtering 을 할 때는 다음과 같은 방법이 있습니다.\n\n위에서 top N개의 feature 선택하는 경우\n\n\ntask <- tsk('penguins')\nlearner <- lrn('classif.rpart')\nfilter <- flt('information_gain')\nfilter$calculate(task)\n\n# top 3개 선택\nkeep <- names(head(filter$scores,3))\ntask$select(keep)\n\n\nscore가 k 보다 큰 경우\n\n\ntask <- tsk('penguins')\nlearner <- lrn('classif.rpart')\nfilter <- flt('information_gain')\nfilter$calculate(task)\n\n# information gain이 0.5보다 큰 경우\nkeep <- names(which(filter$scores>0.5))\ntask$select(keep)\n\n\n\n\n5.3 Wrapper methods\n모델의 성능을 최적화하는 feature들을 반복적으로 선택합니다. feature들에 순위를 매기는 대신, 일부 feature들만을 사용하여 학습한 뒤, 선택된 성능 지표에 따라 평가하게 됩니다.\n\n5.3.1. 간단한 예시\nmlr3에서는 FSelector를 이용하여 위의 방법을 수행합니다.\n\nlibrary(mlr3fselect)\ninstance <- fselect(\n  method='sequential',\n  task= tsk('penguins'),\n  learner = lrn('classif.rpart'),\n  resampling = rsmp('holdout'),\n  measures = msr('classif.acc')\n)\n\n성능 비교를 위한 feature들의 모든 subset을 확인하기 위해선 아래의 코드로 확인 가능합니다.\n\nas.data.table(instance$archive) \n\n최적의 feature 들을 확인하기 위해서는\n\ninstance$result_feature_set\n\n\n\n5.3.2 FSelectInstance\n\n\n5.3.3. Fselector 클래스\nmlr3fselect::FSelector에는 다양한 종류의 feature 선택 알고리즘이 존재합니다.\n\nRandom Search (mlr3fselect::FSelectorRandomSearch)\nExhaustive Search (mlr3fselect::FSelectorExhaustiveSearch)\nSequential Search (mlr3fselect::FSelectorSequential)\nRecursive Feature Elimination (mlr3fselect::FSelectorRFE)\nDesign Points (mlr3fselect::FSelectorDesignPoints)\nGenetic Search (mlr3fselect::FSelectorGeneticSearch)\nShadow Variable Search (mlr3fselect::FSelectorShadowVariableSearch)"
  },
  {
    "objectID": "blog/posts/mlr3_resampling/index.html",
    "href": "blog/posts/mlr3_resampling/index.html",
    "title": "mlr3 리샘플링 벤치마킹",
    "section": "",
    "text": "Important\n\n\n\n이 글은 mlr3book1을 참고하여 작성되었습니다. 국내 R 사용자들에게 잘 알려지지 않은 mlr32 패키지를 통해, R에서도 손쉽게 머신러닝을 수행할 수 있다는 것을 보여드리고자 합니다."
  },
  {
    "objectID": "blog/posts/mlr3_resampling/index.html#resampling-종류",
    "href": "blog/posts/mlr3_resampling/index.html#resampling-종류",
    "title": "mlr3 리샘플링 벤치마킹",
    "section": "Resampling 종류",
    "text": "Resampling 종류\nmlr3 에서 실행가능한 모든 리샘플링 전략은 mlr_resamplings 딕셔너리를 통해 확인가능합니다. 홀드아웃, 교차 검증(CV), 부트스트랩 등이 포함되어있습니다.\n\nas.data.table(mlr_resamplings)\n\n\n\n  \n\n\n\nparams 열을 보면 resampling을 위한 파라미터들이 나와있습니다. 예를 들어 holdout은 ratio를 통해 어떤 비율로 train, test를 나눌 것인지, cv는 folds를 통해 몇 개로 데이터를 나눌 것인지를 설정해줄 수 있죠."
  },
  {
    "objectID": "blog/posts/mlr3_resampling/index.html#resampling-객체-생성",
    "href": "blog/posts/mlr3_resampling/index.html#resampling-객체-생성",
    "title": "mlr3 리샘플링 벤치마킹",
    "section": "Resampling 객체 생성",
    "text": "Resampling 객체 생성\n리샘플링 객체를 만들어봅시다. 우선 holdout을 이용해 리샘플링을 진행하겠습니다. 리샘플링 객체는 rsmp()를 통해 만들 수 있습니다.\n\nresampling <- rsmp(\"holdout\")\nresampling\n\n<ResamplingHoldout>: Holdout\n* Iterations: 1\n* Instantiated: FALSE\n* Parameters: ratio=0.6667\n\n\n생성한 리샘플링 객체를 확인했을 때, Instantiated: FALSE라고 되어있습니다. 아직 리샘플링을 수행하지 않았기 때문입니다.\n또한 holdout 의 ratio를 정해주지 않았기 문에 2/3가 초기값으로 설정되어있습니다. 즉 데이터의 3분의 2는 훈련에, 3분의 1은 검증에 쓰이게 됩니다. 새로운 리샘플링 객체를 만들 때 holdout 비율을 설정하거나 기존의 객체의 파라미터 값을 수정할 수 있습니다.\n\nresampling <- rsmp(\"holdout\", ratio=0.8)\nresampling$param_set$values <- list(ratio=0.5)\n\nholdout은 성능을 일반화하는 과정을 한 번밖에 수행하지 않습니다. 따라서 좀더 신뢰성 있는 성능 측정을 위해, 가장 많이 사용되는 리샘플링 방법 중 하나인 교차 검증(cv)를 사용하도록 하겠습니다.\n\nresampling <- rsmp(\"cv\", folds=10)"
  },
  {
    "objectID": "blog/posts/mlr3_resampling/index.html#instantiation",
    "href": "blog/posts/mlr3_resampling/index.html#instantiation",
    "title": "mlr3 리샘플링 벤치마킹",
    "section": "Instantiation",
    "text": "Instantiation\n데이터가 들어가 있는 태스크에 대해 리샘플링을 수행하기 위해 리샘플링 객체의 $instantiate() 메소드를 이용해야합니다. 메소드 안에 태스크를 넣어주면 리샘플링이 적용됐다는 의미에서 Instantiated: TRUE가 출력됩니다.\n\ntask <- tsk(\"sonar\")\nresampling$instantiate(task)\nresampling\n\n<ResamplingCV>: Cross-Validation\n* Iterations: 10\n* Instantiated: TRUE\n* Parameters: folds=10"
  },
  {
    "objectID": "blog/posts/mlr3_resampling/index.html#실행",
    "href": "blog/posts/mlr3_resampling/index.html#실행",
    "title": "mlr3 리샘플링 벤치마킹",
    "section": "실행",
    "text": "실행\n리샘플리의 실행은 resample() 을 사용합니다.\n\nlearner <- lrn(\"classif.rpart\", predict_type=\"prob\")\nrr <- resample(task, learner, resampling)\nrr\n\n<ResampleResult> of 10 iterations\n* Task: sonar\n* Learner: classif.rpart\n* Warnings: 0 in 0 iterations\n* Errors: 0 in 0 iterations\n\n\n리샘플링 실행이 완료되었고, rr이라는 객체 안에 리샘플링 결과가 저장되어있습니다. 리샘플링을 통한 모델의 성능 평가는 $score()와 $aggregate() 메소드를 이용합니다.\n$score()와 $aggregate() 모두 Measure 객체를 이용해 성능을 측정합니다. 기본적으로 성능을 측정할 때는 검증을 위한 데이터셋을 활용하게 됩니다.\n우선 정확도(classif.acc)를 통해 모델의 정확도를 평가해보겠습니다.\n\nacc <- rr$score(msr(\"classif.acc\"))\nacc[,.(iteration, classif.acc)]\n\n\n\n  \n\n\n\n$score()를 통해 모델의 성능을 살펴보니 cv에서 설정한 10번의 반복 별로 성능이 출력되는 것을 알 수 있습니다.\n다음으로 $aggregate()를 이용해 모델의 성능을 살펴보겠습니다. $aggregate()는 반복 때마다 계산된 성능의 평균 값을 계산하여 출력합니다.\n\nrr$aggregate(msr(\"classif.acc\"))\n\nclassif.acc \n  0.7219048 \n\n\n여러 개의 평가 지표로 모델의 성능을 평가할 수도 있습니다.\n\nmeasures <- msrs(c(\"classif.acc\",\n                   \"classif.sensitivity\",\n                   \"classif.specificity\",\n                   \"classif.auc\"))\n\nrr$aggregate(measures)\n\n        classif.acc classif.sensitivity classif.specificity         classif.auc \n          0.7219048           0.7557955           0.7094017           0.7738624"
  },
  {
    "objectID": "blog/posts/mlr3_resampling/index.html#결과-시각화",
    "href": "blog/posts/mlr3_resampling/index.html#결과-시각화",
    "title": "mlr3 리샘플링 벤치마킹",
    "section": "결과 시각화",
    "text": "결과 시각화\nmlr3viz의 autoplot()을 통해 리샘플링 결과를 시각화할 수 있습니다.\n\nrequire(mlr3viz)\nautoplot(rr, measure = msr(\"classif.acc\"), type=\"boxplot\")\nautoplot(rr, measure = msr(\"classif.acc\"), type=\"histogram\")\n\n\n\n\n\n\nBoxplot\n\n\n\n\n \n\n\n\n\n\nHistogram"
  },
  {
    "objectID": "blog/posts/mlr3_resampling/index.html#벤치마킹-설계하기",
    "href": "blog/posts/mlr3_resampling/index.html#벤치마킹-설계하기",
    "title": "mlr3 리샘플링 벤치마킹",
    "section": "벤치마킹 설계하기",
    "text": "벤치마킹 설계하기\nmlr3에서 벤치마크 실험을 진행하기 위해서는 benchmark_grid() 를 이용해 설계를 해줘야 합니다. 이 때 설계라는 것은 어떤 태스크를 사용할 것인지, 어떤 러너들을 어떻게 리샘플링 할 것인지 등을 조합해주는 것입니다.\nsonar 태스크를 예시로, 분류 모형 중 로지스틱 회귀분석 (classif.log_reg), 의사결정나무(classif.rpart), 랜덤 포레스트(classif.ranger) 러너를 5 Fold 교차검증(CV)으로 비교하도록 설계를 진행하겠습니다.\n\nlibrary(mlr3)\nlibrary(mlr3learners)\ntsk <- tsk(\"sonar\")\nlrns <- lrns(c(\"classif.log_reg\",\"classif.rpart\",\"classif.ranger\"),\n                  predict_type=\"prob\")\nrsmp <- rsmps(\"cv\", folds=5)\ndesign <- benchmark_grid(\n  tasks = tsk,\n  learners = lrns,\n  resamplings = rsmp\n)\nhead(design)"
  },
  {
    "objectID": "blog/posts/mlr3_resampling/index.html#벤치마킹-실험하기",
    "href": "blog/posts/mlr3_resampling/index.html#벤치마킹-실험하기",
    "title": "mlr3 리샘플링 벤치마킹",
    "section": "벤치마킹 실험하기",
    "text": "벤치마킹 실험하기\n벤치마크 설계를 실행하기 위해선 benchmark()함수를 이용합니다.\n\nbmr <- benchmark(design)\nbmr\n\n<BenchmarkResult> of 15 rows with 3 resampling runs\n nr task_id      learner_id resampling_id iters warnings errors\n  1   sonar classif.log_reg            cv     5        0      0\n  2   sonar   classif.rpart            cv     5        0      0\n  3   sonar  classif.ranger            cv     5        0      0\n\n\n벤치마킹이 끝났다면, $aggregate() 를 이용해 성능을 검증해보면 됩니다. 분류의 정확도를 예시로 살펴보겠습니다.\n\nacc <- bmr$aggregate(msr(\"classif.acc\"))\nacc[,.(task_id, learner_id, classif.acc)]"
  },
  {
    "objectID": "blog/posts/mlr3_resampling/index.html#벤치마크결과-객체-살펴보기",
    "href": "blog/posts/mlr3_resampling/index.html#벤치마크결과-객체-살펴보기",
    "title": "mlr3 리샘플링 벤치마킹",
    "section": "벤치마크결과 객체 살펴보기",
    "text": "벤치마크결과 객체 살펴보기\n벤치마크결과(BenchmarkResult) 객체는 리샘플링결과(ResampleResult) 객체의 집합입니다. 이 객체는 $resample_result(i) 메소드를 이용해 리샘플링 결과를 추출할 수 있습니다. 이 때, i는 벤치마크 실험번호를 의미합니다. 위의 예시는 세 가지 러너로 벤치마킹을 했기 때문에, i는 러너를 의미합니다.\n\nrr_lr <- bmr$resample_result(1)\nrr_rpart <- bmr$resample_result(2)\nrr_ranger <- bmr$resample_result(3)\nrr_lr\n\n<ResampleResult> of 5 iterations\n* Task: sonar\n* Learner: classif.log_reg\n* Warnings: 0 in 0 iterations\n* Errors: 0 in 0 iterations\n\n\n\nrr_ranger\n\n<ResampleResult> of 5 iterations\n* Task: sonar\n* Learner: classif.ranger\n* Warnings: 0 in 0 iterations\n* Errors: 0 in 0 iterations\n\n\nResampleResult 객체들은 as_benchmark_result() 함수를 이용해 다시 BenchmarkResult로 변환될 수 있습니다. 또한 c()를 이용해 묶을 수 있습니다.\n\nbmr1 = as_benchmark_result(rr_rpart)\nbmr2 = as_benchmark_result(rr_ranger)\n\nbmr_combined = c(bmr1, bmr2)\nbmr_combined$aggregate(msr(\"classif.acc\"))\n\n\n\n  \n\n\n\n\nlibrary(mlr3viz)\nautoplot(bmr, measure=msr(\"classif.acc\"))"
  },
  {
    "objectID": "blog/posts/regular expression/index.html",
    "href": "blog/posts/regular expression/index.html",
    "title": "stringr을 이용한 문자 추출하기",
    "section": "",
    "text": "아래와 같은 문자열 데이터가 있다고 가정해봅시다.\n\n\n [1] \"                         location         age year  sales\"\n [2] \"1          South-East Asia Region   <20 years 2002 0.01\"  \n [3] \"2      Western Sub-Saharan Africa 20-24 years 2010 0.04\"  \n [4] \"3      Commonwealth Middle Income 40-44 years 2003 0.18\"  \n [5] \"4                  Eastern Europe 45-49 years 2008 0.37\"  \n [6] \"5  World Bank Lower Middle Income   <20 years 2005 0.01\"  \n [7] \"6                         Oceania 45-49 years 2006 0.26\"  \n [8] \"7      Commonwealth Middle Income 55-59 years 2004 0.30\"  \n [9] \"8      Western Sub-Saharan Africa 30-34 years 1997 0.04\"  \n[10] \"9        High-income Asia Pacific 65-74 years 2000 0.24\"  \n\n\n비록 문자 형태의 벡터이지만, 열 단위로 묶인 데이터프레임의 형태를 띄고 있습니다.\n저 문자열 속에서 location, age, year, sales 를 나눠 데이터프레임으로 만들어주려면 (일일이 복붙하면서 데이터프레임으로 선언하는 노가다를 해야 합니다) 정규표현식(Regular expression)을 사용해야 합니다.\n정규표현식 규칙은 크게 다음과 같습니다.\n\n숫자: \\\\d 또는 [:digit:]\n문자: [:alpha:]\n숫자 또는 문자: [:alnum:]\n0개 이상: *\n한 개 이상: +\n시작하는 단어: ^\n끝나는 단어: $\n구두점 등의 특수문자: [:punct:] 또는 [:symbol:] 또는 \\\\특수기호\nR에서 특수문자 정규표현식을 찾을 때, 사용될 특수문자에 따라 [:punct:] 또는 [:symbol:]을 사용해야 합니다.\n\nlibrary(stringi)\nascii <- stri_enc_fromutf32(1:127)\nmessage(\"Punct: \", stri_extract_all_regex(ascii, \"[[:punct:]]\")[[1]])\nmessage(\"Symbol: \", stri_extract_all_regex(ascii, \"[[:symbol:]]\")[[1]])\n\n\n\n\n여러 가지 규칙을 한 번에 찾을 때, 규칙이 긴 것부터 찾는다. 다시 말해 찾고자 하는 단어가 긴 단어의 규칙을 먼저 입력해야 한다.\n\n여러 개의 패턴을 적용할 때 | 을 단위로 정규표현식을 찾아줄 수가 있습니다. paste() 또는 paste0() 함수의 collapse를 이용하여 여러 패턴을 붙여줄 수 있습니다.\n자 이제 처음에 보여드렸던 문자 데이터에서 각각의 데이터를 추출하여 데이터프레임으로 만들어보겠습니다. 가장 먼저 location 입니다.\n지역이 굉장히 다양하고, 또 단어마다 규칙들이 많아 찾기가 어려운 규칙입니다.\n\nlibrary(stringr)\nf <- \"[:alpha:]+ [:alpha:]+ [:alpha:]+ [:alpha:]+ [:alpha:]+\"\ng <- \"[:alpha:]+-[:alpha:]+ [:alpha:]+ - [:alpha:]+\"\nd <- \"[:alpha:]+-[:alpha:]+ [:alpha:]+ [:alpha:]+\"\nh <- \"[:alpha:]+ [:alpha:]+-[:alpha:]+ [:alpha:]+\"\na <-  \"[:alpha:]+ [:alpha:]+ [:alpha:]+\"\nc <- \"[:alpha:]+ [:alpha:]+-[:alpha:]+\"\ne <- \"[:alpha:]+ [:alpha:]+\"\nb <-  \"[:alpha:]+\"\nptrn_loc <- paste0(c(f,g,d,h,a,c,e,b),collapse = \"|\")\n\nloc <- str_extract(\n  string = temp[2:length(temp)],\n  pattern = ptrn_loc)\n\nhead(loc)\n\n[1] \"South-East Asia Region\"         \"Western Sub-Saharan Africa\"    \n[3] \"Commonwealth Middle Income\"     \"Eastern Europe\"                \n[5] \"World Bank Lower Middle Income\" \"Oceania\"                       \n\n\n다음은 age를 찾아보겠습니다. age를 살펴보면, 네 가지 정도로 분류할 수 있습니다. 50-54 형태, 80+ 형태 <20 형태, 그리고 All ages가 있죠.\n\naa <- \"[:digit:]{2}-[:digit:]{2} years\"\nbb <- \"\\\\<[:digit:]{2}+ years\"\ncc <- \"[:digit:]{2}\\\\+ years\"\ndd <- \"All ages\" # all ages\nptrn_age <- paste0(c(aa,bb,cc,dd),collapse = \"|\")\nages <- str_extract(\n  string = temp[2:length(temp)],\n  pattern = ptrn_age\n)\n\nhead(ages)\n\n[1] \"<20 years\"   \"20-24 years\" \"40-44 years\" \"45-49 years\" \"<20 years\"  \n[6] \"45-49 years\"\n\n\n나머지 year와 sales는 앞의 두 가지보다 간단합니다.\n\nyear <- str_extract(\n  string = temp[2:length(temp)],\n  pattern = \"[:digit:]{4}\"\n) |> as.numeric()\n\nhead(year)\n\n[1] 2002 2010 2003 2008 2005 2006\n\nsales <- str_extract(\n  string = temp[2:length(temp)],\n  pattern = \"[:digit:]{1}\\\\.[:digit:]{2}\"\n) |> as.numeric()\n\nhead(sales)\n\n[1] 0.01 0.04 0.18 0.37 0.01 0.26\n\n\n이제 위에서 추출한 loc, ages, year, sales를 하나의 데이터프레임으로 만들어주면 끝입니다.\n\ndf <- data.frame(\n  location = loc,\n  age = ages,\n  year = year,\n  sales = sales\n)\n\nhead(df)\n\n\n\n  \n\n\n\n\n레퍼런스\n\nhttps://continuous-development.tistory.com/33\nhttps://stackoverflow.com/questions/26348643/r-regex-with-stringi-icu-why-is-a-considered-a-non-punct-character"
  },
  {
    "objectID": "gallery/gallery/exponential graph/index.html",
    "href": "gallery/gallery/exponential graph/index.html",
    "title": "지수함수를 통한 복리 비교",
    "section": "",
    "text": "require(ggplot2)\ndf <- data.frame(x=seq(1,50))\nx <- 1:50\np <- ggplot(df, aes(x=x))\nfor(i in 1:8){\n  p = local({\n    j <- i\n    y <- (1+0.01*j)^x\n    p + geom_line(aes(y=y, color=as.character(j)),\n                  linewidth=1) +\n      annotate(\"text\",\n               label = 0.01*j,\n               size=2,\n               x=50, y=(1+0.01*j)^50,\n               hjust = -.3)\n  }\n  )\n}\n\np + scale_color_brewer(\n  palette = \"Spectral\") +\n  theme_classic()+\n  scale_x_continuous(limits=c(0,55))+\n  theme(legend.position = \"None\") +\n  labs(x=\"Year\", y=\"Total\")"
  },
  {
    "objectID": "gallery/gallery/ggplot2_forestplot/index.html",
    "href": "gallery/gallery/ggplot2_forestplot/index.html",
    "title": "ggplot2를 활용한 forestplot 그리기",
    "section": "",
    "text": "ggplot2 를 이용한 예쁜 forest plot 만들기\n\ndf_data <- data.frame(Cancer=c(\"Brain\", \"Colorectal\", \"Kidney clear cell carcinoma\", \"Kidney renal papillary carcinoma\"),\n                      OR=c(1.03, 0.98, 1.27, 1.22),\n                      OR_lower=c(0.97, 0.62, 1.16, 1.03),\n                      OR_upper=c(1.09, 1.55, 1.38, 1.45)\n                      )\n\n### Visualize\n\nif (!require('ggplot2')) install.packages('ggplot2'); library('ggplot2')   # Load ggplot2 library\n\n\n\np <- ggplot(df_data, aes(x=Cancer, y=OR, ymin=OR_lower, ymax=OR_upper)) + \n  geom_linerange(size=8, colour=\"#a6d8f0\") +\n  geom_hline(aes(x=0, yintercept=1), lty=1) +\n  geom_point(size=3, shape=21, fill=\"#008fd5\", colour = \"white\", stroke = 1) +\n  scale_y_continuous(limits = c(0.5, 2)) +\n  coord_flip() +\n  ggtitle(\"Odds ratio for Gene of Interest\") +\n  theme_minimal()\np"
  },
  {
    "objectID": "gallery/gallery/ml_model_performance/index.html",
    "href": "gallery/gallery/ml_model_performance/index.html",
    "title": "머신러닝 모델별 퍼포먼스 그래프",
    "section": "",
    "text": "아래와 같이 모델별로 머신러닝 성능을 정리한 표가 있다고 해보자.\n\n이 데이터를 통해 머신러닝 모델별, 그리고 질병별 성능을 아래와 같이 시각화해보자. X축에는 모델이, Y축에는 성능이 와야 하고, 각 성능 지표별로 다른 선으로 구성할 것이다. 그리고 각 질병별로 이런 그래프가 나열되어야 한다.\n\n우선 데이터 시각화를 위한 데이터프레임을 만들어야 한다. 저 표 형태 그대로는 데이터프레임으로 저장할 수 없다. 따라서 데이터 프레임 형태를 잘 구성하는 게 중요하다.\n특정 범주별로 색상을 구분해주는 그래프를 만들기 위해선 X축과 범례에 들어갈 범주 데이터, 그리고 수치에 해당하는 숫자 데이터를 각각 다른 열로 구성해야 한다.\n우선 각 모델별 성능별 점수가 질병별로 필요하므로, 질병 열을 구성해준다. 위의 표에서 질병 * 모델 * 성능을 봤을 때, 하나의 행이 질병 하나의 모델별 성능별 점수인 것을 알 수 있다. 따라서 질병에 따라 모델, 성능, 점수가 길게 늘어지는 long data가 되도록 구성한다.\n\nrequire(data.table)\nrequire(ggplot2)\nrequire(ggthemes)\ndf <- data.table(\n  disease = rep(c(\"Death\",\"Heart disease\",\"Stroke\",\"Cancer\",\"Hypertension\",\"Diabetes\"), each=12),\n  model = rep(rep(c(\"Mod1\",\"Mod2\",\"Mod3\",\"Mod4\"),each=3),6),\n  category = rep(c(\"AUC\",\"Accuracy\",\"F1\"), 4*6),\n  score = c(0.863, 0.725, 0.106, 0.873, 0.753, 0.116, 0.877, 0.802, 0.135, 0.887, 0.793, 0.135,\n            0.718,  0.617,  0.213,  0.731,  0.653, 0.224,   0.731,  0.605,  0.216,  0.734,  0.614,  0.218,\n            0.790,  0.684,  0.223,  0.794,  0.681, 0.223,   0.794,  0.713,  0.234,  0.795,  0.705,  0.233,\n            0.774,  0.654,  0.123,  0.775,  0.669, 0.126,   0.776,  0.665,  0.125,  0.783,  0.690,  0.131,\n            0.698,  0.615,  0.434,  0.720,  0.595, 0.449,   0.769,  0.662,  0.492,  0.770,  0.665,  0.493,\n            0.706,  0.592,  0.324,  0.725,  0.615, 0.336,   0.806,  0.699,  0.400,  0.809,  0.726,  0.413\n            )\n)\ndf |> head(12)\n\n\n\n  \n\n\n\n하나의 질병 당 모델 네 종류, 그리고 모델 성능 세 종류가 필요하다. 그렇기 떄문에 하나의 질병을 12번씩 반복하여 만들어주면 된다.\n다음으로 원하는 순서대로 출력하기 위해, 질병의 순서와 모델 성능의 순서를 정해준다.\n\ndf$disease <- factor(df$disease, levels=c(\"Death\",\"Heart disease\",\"Stroke\",\"Cancer\",\"Hypertension\",\"Diabetes\"))\ndf$category <- factor(df$category, levels=c(\"AUC\",\"Accuracy\",\"F1\"))\n\n그리고 나서 질병 * 모델 * 성능 지표 별 점수를 시각화해준다.\n\n df |> \n  ggplot(aes(x=model, y=score, color=category, group=category))+\n  geom_point(aes(shape=category)) + \n  geom_line(aes(lty=category)) + \n  facet_grid(~disease) +\n  scale_x_discrete(labels=c(\"Model 1\", \"Model 2\", \"Model 3\", \"Model 4\"))+\n  scale_y_continuous(limits = c(0,1),\n                     breaks = seq(0,1,0.2),\n                     expand = c(0,0)) + \n  scale_shape_discrete(labels=c(\"AUC\",\"Accuracy\",\"F1-score\"),\n                       name = NULL)+\n  scale_color_tableau(labels=c(\"AUC\",\"Accuracy\",\"F1-score\"),\n                       name = NULL)+\n  scale_linetype_discrete(labels=c(\"AUC\",\"Accuracy\",\"F1-score\"),\n                          name = NULL)+\n  geom_text(aes(label=format(score,3)), vjust=-1, size=1.5) +\n  theme_few() +\n  theme(legend.position = \"top\",\n        legend.direction = \"horizontal\",\n        axis.title = element_blank(),\n        legend.text = element_text(size=7),\n        axis.text = element_text(size=4),\n        strip.text = element_text(size=6, face = \"bold\")) +\n  ggtitle(\"(A) Male (n=64,389)\")\n\n\n\n\n질병은 facet_grid()에 포함시켜 옆으로 나열하게끔 시각화 하였다."
  },
  {
    "objectID": "gallery/index.html",
    "href": "gallery/index.html",
    "title": "Gallery",
    "section": "",
    "text": "Order By\n       Default\n         \n          Title\n        \n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\n\n \n\n\n\n지수함수를 통한 복리 비교\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n머신러닝 모델별 퍼포먼스 그래프\n\n\n\nMachine learning\n\n\nggplot2\n\n\n\n\n\n\n\n\n\n\nMar 3, 2023\n\n\n\n\n\n\n\n\n\n\n \n\n\n\nggplot2를 활용한 forestplot 그리기\n\n\n\nR\n\n\nggplot2\n\n\nforestplot\n\n\n\n\n\n\n\n\n\n\nJan 1, 2023\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Rchemist 블로그",
    "section": "",
    "text": "Order By\n       Default\n         \n          Title\n        \n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n  \n\n\n\n\nmlr3 하이퍼파라미터 최적화\n\n\n\n\n\n\n\nR\n\n\nmlr3\n\n\nmachine learning\n\n\n\n\nmlr3를 이용한 하이퍼파라미터 튜닝 학습\n\n\n\n\n \n\n\n\n\n  \n\n\n\n\n학습관점에서 비교하는 dplyr과 data.table\n\n\n\n\n\n\n\ndata.table\n\n\ndplyr\n\n\nR\n\n\n\n\n처음 배우는 사람에게 추천하는 패키지\n\n\n\n\n\n\nFeb 27, 2023\n\n\n\n\n\n\n  \n\n\n\n\nmlr3 리샘플링 벤치마킹\n\n\n\n\n\n\n\nmlr3\n\n\nR\n\n\nmachine learning\n\n\n\n\n여러 모델 동시 학습 및 성능비교\n\n\n\n\n\n\nFeb 24, 2023\n\n\n\n\n\n\n  \n\n\n\n\nstringr을 이용한 문자 추출하기\n\n\n\n\n\n\n\nR\n\n\nregex\n\n\nstringr\n\n\n\n\n정규표현식을 사용한 규칙 찾기\n\n\n\n\n\n\nFeb 23, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggplot2 facet label 설정\n\n\n\n\n\n\n\nR\n\n\nggplot2\n\n\nfacet\n\n\n\n\nggplot에서 facet을 사용할 때 label을 변경하는 방법에 대해 알아봅시다.\n\n\n\n\n\n\nFeb 22, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ndata.table 1.14.9 업데이트\n\n\n\n\n\n\n\nR\n\n\ndata.table\n\n\n\n\ndata.table 1.14.9 버전에서 업데이트 될 내용을 살펴봅시다.\n\n\n\n\n\n\nFeb 21, 2023\n\n\n\n\n\n\n  \n\n\n\n\nmlr3 기초\n\n\n\n\n\n\n\nmlr3\n\n\nR\n\n\nmachine learning\n\n\n\n\nmlr3에 대한 소개 및 mlr3를 사용하기 위한 필수문법에 대해 소개합니다.\n\n\n\n\n\n\nFeb 20, 2023\n\n\n\n\n\n\n  \n\n\n\n\nImputation의 종류\n\n\n\n\n\n\n\nR\n\n\nimputation\n\n\nmice\n\n\n\n\nmice를 이용한 multiple imputation\n\n\n\n\n\n\nFeb 18, 2023\n\n\n\n\n\n\n  \n\n\n\n\nggplot 세부 조정: 축 조정\n\n\n\n\n\n\n\nR\n\n\nggplot2\n\n\nvisualization\n\n\n\n\n그래프와 축 간격을 조정하거나 tick 간격을 변경하는 방법\n\n\n\n\n\n\nFeb 12, 2023\n\n\n\n\n\n\n  \n\n\n\n\nggsignif: 통계적 유의성 시각화\n\n\n\n\n\n\n\nR\n\n\nggplot2\n\n\nvisualization\n\n\nggsignif\n\n\n\n\n그래프에 통계적 유의성(p-value) 출력\n\n\n\n\n\n\nFeb 12, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDataExplorer을 활용한 EDA\n\n\n\n\n\n\n\nEDA\n\n\nR\n\n\n\n\nDataExplorer를 통한 탐색적 데이터 분석\n\n\n\n\n\n\nFeb 9, 2023\n\n\n\n\n\n\n  \n\n\n\n\ntidyr로 Pivoting하기\n\n\n\n\n\n\n\nR\n\n\ndplyr\n\n\ntidyr\n\n\n\n\ntidyr을 이용해 데이터의 형태를 바꾸는 pivoting에 대해 알아봅시다.\n\n\n\n\n\n\nFeb 3, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ndplyr 심화: across()\n\n\n\n\n\n\n\ndplyr\n\n\nR\n\n\n\n\nacross()로 배우는 열 동시 처리\n\n\n\n\n\n\nFeb 2, 2023\n\n\n\n\n\n\n  \n\n\n\n\nggplot에서 두 번째 y축 그리기\n\n\n\n\n\n\n\nggplot2\n\n\nR\n\n\nVisualization\n\n\naxis\n\n\n\n\nggplot으로 그래프에 두 개의 y축을 활용하는 방법을 배우기\n\n\n\n\n\n\nFeb 2, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ndplyr 기초 문법 이해하기\n\n\n\n\n\n\n\ndplyr\n\n\nR\n\n\n\n\n파이프 연산자와 함께 dplyr 필수 함수들과 문법을 알아봅시다.\n\n\n\n\n\n\nFeb 1, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ndplyr group_by\n\n\n\n\n\n\n\ndplyr\n\n\nR\n\n\n\n\ndplyr를 활용한 그룹별 데이터 처리\n\n\n\n\n\n\nFeb 1, 2023\n\n\n\n\n\n\n  \n\n\n\n\nR에서 색상 다루기\n\n\n\n\n\n\n\ncolor\n\n\nR\n\n\nvisualization\n\n\n\n\n데이터 시각화를 진행할 때, 그래프에 적절한 색상을 선택하는 방법을 살펴봅시다.\n\n\n\n\n\n\nJan 25, 2023\n\n\n\n\n\n\n  \n\n\n\n\nQuarto 사용법\n\n\nQuarto, a substitute of Rmarkdown\n\n\n\n\nQuarto\n\n\nR\n\n\n\n\nBrief intorduction of Quarto\n\n\n\n\n\n\nJan 19, 2023\n\n\n\n\n\n\n  \n\n\n\n\nR 기초 이해\n\n\n\n\n\n\n\nR\n\n\ndata.frame\n\n\n\n\nR 사용을 위한 필수 개념 및 함수을 배워봅시다.\n\n\n\n\n\n\nJan 19, 2023\n\n\n\n\n\n\n  \n\n\n\n\nggplot boxplot 그리기\n\n\n\n\n\n\n\nggplot2\n\n\nR\n\n\nVisualization\n\n\nboxplot\n\n\n\n\nggplot으로 boxplot 그리는 방법\n\n\n\n\n\n\nJan 19, 2023\n\n\n\n\n\n\n  \n\n\n\n\ndata.table 심화\n\n\n\n\n\n\n\ndata.table\n\n\nR\n\n\n\n\n특수 기호, 조인, 피봇 등 data.table에서 다루는 심화내용을 살펴봅시다.\n\n\n\n\n\n\nJan 19, 2023\n\n\n\n\n\n\n  \n\n\n\n\ndata.table 기초 문법\n\n\n\n\n\n\n\ndata.table\n\n\nR\n\n\n\n\ndata.table 문법, 연산자, 함수\n\n\n\n\n\n\nJan 18, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nObservable.js\n\n\n\n\n\n\n\nOJS\n\n\nVisualization\n\n\njavascript\n\n\n\n\nInteractive chart with ojs\n\n\n\n\n\n\nJan 1, 2023\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "헬스케어 빅데이터를 다루는 데이터사이언티스트입니다. 😃\n\nSkillsLanguagesEducationExperience\n\n\n\n\n\n\n\n\n\n\n\nKOR 🇰🇷: Native\nENG 🇺🇸 : Intermediate\nCHN 🇨🇳: Intermediate\nFRE 🇫🇷: Beginner\n\n\n\n\nMPH, Graduate School of Public Health, Seoul National University\nBS, Chinese language and literature, Konkuk University\n\n\n\n\nComento | Mentor | Sept 2022 - present\nSNUBH | Data scientist | June 2021 - present"
  },
  {
    "objectID": "blog/index.html",
    "href": "blog/index.html",
    "title": "Posts",
    "section": "",
    "text": "Order By\n       Default\n         \n          Title\n        \n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n  \n\n\n\n\nmlr3 하이퍼파라미터 최적화\n\n\n\n\n\n\n\nR\n\n\nmlr3\n\n\nmachine learning\n\n\n\n\nmlr3를 이용한 하이퍼파라미터 튜닝 학습\n\n\n\n\n \n\n\n\n\n  \n\n\n\n\n학습관점에서 비교하는 dplyr과 data.table\n\n\n\n\n\n\n\ndata.table\n\n\ndplyr\n\n\nR\n\n\n\n\n처음 배우는 사람에게 추천하는 패키지\n\n\n\n\n\n\nFeb 27, 2023\n\n\n\n\n\n\n  \n\n\n\n\nmlr3 리샘플링 벤치마킹\n\n\n\n\n\n\n\nmlr3\n\n\nR\n\n\nmachine learning\n\n\n\n\n여러 모델 동시 학습 및 성능비교\n\n\n\n\n\n\nFeb 24, 2023\n\n\n\n\n\n\n  \n\n\n\n\nstringr을 이용한 문자 추출하기\n\n\n\n\n\n\n\nR\n\n\nregex\n\n\nstringr\n\n\n\n\n정규표현식을 사용한 규칙 찾기\n\n\n\n\n\n\nFeb 23, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggplot2 facet label 설정\n\n\n\n\n\n\n\nR\n\n\nggplot2\n\n\nfacet\n\n\n\n\nggplot에서 facet을 사용할 때 label을 변경하는 방법에 대해 알아봅시다.\n\n\n\n\n\n\nFeb 22, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ndata.table 1.14.9 업데이트\n\n\n\n\n\n\n\nR\n\n\ndata.table\n\n\n\n\ndata.table 1.14.9 버전에서 업데이트 될 내용을 살펴봅시다.\n\n\n\n\n\n\nFeb 21, 2023\n\n\n\n\n\n\n  \n\n\n\n\nmlr3 기초\n\n\n\n\n\n\n\nmlr3\n\n\nR\n\n\nmachine learning\n\n\n\n\nmlr3에 대한 소개 및 mlr3를 사용하기 위한 필수문법에 대해 소개합니다.\n\n\n\n\n\n\nFeb 20, 2023\n\n\n\n\n\n\n  \n\n\n\n\nImputation의 종류\n\n\n\n\n\n\n\nR\n\n\nimputation\n\n\nmice\n\n\n\n\nmice를 이용한 multiple imputation\n\n\n\n\n\n\nFeb 18, 2023\n\n\n\n\n\n\n  \n\n\n\n\nggplot 세부 조정: 축 조정\n\n\n\n\n\n\n\nR\n\n\nggplot2\n\n\nvisualization\n\n\n\n\n그래프와 축 간격을 조정하거나 tick 간격을 변경하는 방법\n\n\n\n\n\n\nFeb 12, 2023\n\n\n\n\n\n\n  \n\n\n\n\nggsignif: 통계적 유의성 시각화\n\n\n\n\n\n\n\nR\n\n\nggplot2\n\n\nvisualization\n\n\nggsignif\n\n\n\n\n그래프에 통계적 유의성(p-value) 출력\n\n\n\n\n\n\nFeb 12, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDataExplorer을 활용한 EDA\n\n\n\n\n\n\n\nEDA\n\n\nR\n\n\n\n\nDataExplorer를 통한 탐색적 데이터 분석\n\n\n\n\n\n\nFeb 9, 2023\n\n\n\n\n\n\n  \n\n\n\n\ntidyr로 Pivoting하기\n\n\n\n\n\n\n\nR\n\n\ndplyr\n\n\ntidyr\n\n\n\n\ntidyr을 이용해 데이터의 형태를 바꾸는 pivoting에 대해 알아봅시다.\n\n\n\n\n\n\nFeb 3, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ndplyr 심화: across()\n\n\n\n\n\n\n\ndplyr\n\n\nR\n\n\n\n\nacross()로 배우는 열 동시 처리\n\n\n\n\n\n\nFeb 2, 2023\n\n\n\n\n\n\n  \n\n\n\n\nggplot에서 두 번째 y축 그리기\n\n\n\n\n\n\n\nggplot2\n\n\nR\n\n\nVisualization\n\n\naxis\n\n\n\n\nggplot으로 그래프에 두 개의 y축을 활용하는 방법을 배우기\n\n\n\n\n\n\nFeb 2, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ndplyr 기초 문법 이해하기\n\n\n\n\n\n\n\ndplyr\n\n\nR\n\n\n\n\n파이프 연산자와 함께 dplyr 필수 함수들과 문법을 알아봅시다.\n\n\n\n\n\n\nFeb 1, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ndplyr group_by\n\n\n\n\n\n\n\ndplyr\n\n\nR\n\n\n\n\ndplyr를 활용한 그룹별 데이터 처리\n\n\n\n\n\n\nFeb 1, 2023\n\n\n\n\n\n\n  \n\n\n\n\nR에서 색상 다루기\n\n\n\n\n\n\n\ncolor\n\n\nR\n\n\nvisualization\n\n\n\n\n데이터 시각화를 진행할 때, 그래프에 적절한 색상을 선택하는 방법을 살펴봅시다.\n\n\n\n\n\n\nJan 25, 2023\n\n\n\n\n\n\n  \n\n\n\n\nQuarto 사용법\n\n\nQuarto, a substitute of Rmarkdown\n\n\n\n\nQuarto\n\n\nR\n\n\n\n\nBrief intorduction of Quarto\n\n\n\n\n\n\nJan 19, 2023\n\n\n\n\n\n\n  \n\n\n\n\nR 기초 이해\n\n\n\n\n\n\n\nR\n\n\ndata.frame\n\n\n\n\nR 사용을 위한 필수 개념 및 함수을 배워봅시다.\n\n\n\n\n\n\nJan 19, 2023\n\n\n\n\n\n\n  \n\n\n\n\nggplot boxplot 그리기\n\n\n\n\n\n\n\nggplot2\n\n\nR\n\n\nVisualization\n\n\nboxplot\n\n\n\n\nggplot으로 boxplot 그리는 방법\n\n\n\n\n\n\nJan 19, 2023\n\n\n\n\n\n\n  \n\n\n\n\ndata.table 심화\n\n\n\n\n\n\n\ndata.table\n\n\nR\n\n\n\n\n특수 기호, 조인, 피봇 등 data.table에서 다루는 심화내용을 살펴봅시다.\n\n\n\n\n\n\nJan 19, 2023\n\n\n\n\n\n\n  \n\n\n\n\ndata.table 기초 문법\n\n\n\n\n\n\n\ndata.table\n\n\nR\n\n\n\n\ndata.table 문법, 연산자, 함수\n\n\n\n\n\n\nJan 18, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nObservable.js\n\n\n\n\n\n\n\nOJS\n\n\nVisualization\n\n\njavascript\n\n\n\n\nInteractive chart with ojs\n\n\n\n\n\n\nJan 1, 2023\n\n\n\n\n\n\nNo matching items"
  }
]