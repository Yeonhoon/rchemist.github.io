---
title: 'mlr3 Resampling & benchmarking'
description: "mlr3를 활용한 validation 및 모델 벤치마킹"
date: "2023-02-20"
categories: [mlr3, R, machine learning]
---

```{r message=FALSE, warning=FALSE}
install.packages("data.table")
library(data.table)
library(mlr3)
library(mlr3verse)
library(mlr3viz)
```

## 3. Resampling

```{r}
# holdout: train-test split
# Instantiate: F --> 아직 resample 안됨.

task_sonar <- tsk("sonar")
lrn_rf <- lrn("classif.ranger", predict_type="prob")
resamp <- rsmp("holdout")
measures <- msrs(c("classif.acc",
                   "classif.sensitivity",
                   "classif.specificity",
                   "classif.auc"))
print(resamp)

resamp$instantiate(task_sonar)
train <- resamp$train_set(1)
test <- resamp$test_set(1)

resamp <- rsmp('cv', folds=5)
rr <- resample(task_sonar, lrn_rf, resamp, store_models = T)

rr$aggregate(measures)
```

```{r}
autoplot(rr, type='prc')
```

## 4. Benchmarking

different learners on multiple tasks and/or different resampling

### 1) Design

```{r}
library(mlr3)
library(mlr3learners)
design <- benchmark_grid(
  tasks = tsk('sonar'),
  learners = lrns(c('classif.log_reg','classif.ranger'),
                  predict_type='prob',
                  predict_sets=c('train','test')),
  resamplings = rsmps('cv',folds=5)
)
design
```

### 2) Execution

```{r}
bmr <- benchmark(design, store_models = T)

measures <- list(
  msr('classif.acc',id='accuracy'),
  msr('classif.auc',id='AUC'),
  msr('classif.prauc',id='PRC')
)

bmr$aggregate(measures)
```

### 3) Plotting

```{r}
require(ggthemes)
require(ggpubr)
autoplot(bmr, type='roc')
```

## 4. Hyperparameter tuning {#sec-hyperparameter}

```{r}
lrn_rf$param_set
require(paradox)
lrn_rf <- lrn('classif.ranger',
              max.depth=to_tune(10,50),
              mtry = to_tune(5,20),
              num.trees = to_tune(30,100)
              )

# ti: TuningInstance
instance <- ti(
  task = task_sonar,
  learner = lrn_rf,
  resampling = rsmp('cv',folds=5),
  measures = msrs(c('classif.sensitivity',
                    'classif.specificity')),
  terminator = trm('evals',n_evals=100)
)
instance
tuner = tnr('random_search')

tuner$optimize(instance)

```

```{r}
lrn_rf$param_set$values <- instance$result_learner_param_vals[[1]]

lrn_rf
```

### AutoTuner

```{r}
lrn_xgb <- lrn('classif.xgboost',
               eta = to_tune(1e-4,1e-2),
               gamma=to_tune(1e-3,1e-2),
               max_depth=to_tune(10,50),
               predict_type='prob'
               )

at <- auto_tuner(
  method=tnr('random_search'),
  learner = lrn_xgb,
  resampling = rsmp('cv',folds=5),
  measure = msr('classif.auc'),
  term_evals = 30
)

at$train(task_sonar)
```

### Nested Resampling

```{r}
outer_resampling <- rsmp('cv',folds=3)

rr <- resample(task_sonar, at, outer_resampling, store_models = T)

extract_inner_tuning_results(rr)
rr$score(measures)
rr$aggregate(measures)
```

## 5. Feature selection

### 5.1. Introduction

feature selection의 장점

1.  과적합(overfitting) 감소로 인한 성능 향상
2.  불필요한 feature에 의존하지 않는 안정된(robust) 모델
3.  간단함으로 인한 해석의 용이함
4.  잠재적으로 값비싼 feature 수집 불필요

### 5.2. Filters

#### 5.2.1 Filter value 계산

`mlr3filters::mlr_filters` dictionary 통해 또는 `mlr3filters::flt()` 를 이용해 filter 선택 가능.

Filter 클래스에는 `$calculate()` 메소드가 존재하는데, filter value와 등수를 내림차순 정렬하여 보여준다.

예를 들어 information gain filter를 이용하는 경우,

```{r}
library(mlr3verse)
filter <- flt('information_gain')
task <- tsk('penguins')
task
filter$calculate(task)
filter

```

일부 filter들은 hyperparameters가 존재하는데, learner에서 param_set을 변경해주는 것처럼 간단히 변경 가능합니다.

```{r}
filter_cor <- flt('correlation')
filter_cor$param_set$values <- list(method='spearman')
filter_cor$param_set
```

#### 5.2.2. Feature importance filters

importance 가 있는 모든 모델에서 사용 가능한 filter입니다. `ranger`와 같은 일부 learner에서는 learner를 만들 때 지정을 해줘야 합니다.

```{r}
lrn_rf <- lrn('classif.ranger', importance='impurity')

# remove missing values
task$filter(which(complete.cases(task$data())))

filter_imp <- flt('importance', learner=lrn_rf)
filter_imp$calculate(task)
filter_imp
```

#### 5.2.3. Embedded methods

Embedded methods는 Learner들로 하여금 예측에 중요한 변수들을 선택하는 방법입니다. 많은 learner들이 이 기능을 갖고 있습니다.

```{r}
task <- tsk('penguins')
learner <- lrn('classif.rpart')

stopifnot('selected_features' %in% learner$properties)

learner$train(task)
learner$selected_features()

filter <- flt('selected_features', learner=learner)
filter$calculate(task)
filter
```

model에 의해 선택된 feature의 점수만 1, 나머지는 0 (dropped features)

#### 5.2.4. Filter-based feature selection

filter를 통해 각 feature들의 점수가 계산이 되었다면, 다음 모델링 단계에서 feature를 선택하여 학습을 시켜주어야 합니다.

```{r}
task <- tsk('penguins')
learner <- lrn('classif.rpart')
filter <- flt('selected_features', learner=learner)
filter$calculate(task)

keep <- names(which(filter$scores==1))
task$select(keep) # column을 선택하기 때문에 select
task$feature_names
```

위의 예시에서는 selected_features를 했기 때문에 0과 1로 구분이 되었지만, 연속형 점수에 대해 filtering 을 할 때는 다음과 같은 방법이 있습니다.

-   위에서 top N개의 feature 선택하는 경우

    ```{r}
    task <- tsk('penguins')
    learner <- lrn('classif.rpart')
    filter <- flt('information_gain')
    filter$calculate(task)

    # top 3개 선택
    keep <- names(head(filter$scores,3))
    task$select(keep)
    ```

-   score가 k 보다 큰 경우

    ```{r}
    task <- tsk('penguins')
    learner <- lrn('classif.rpart')
    filter <- flt('information_gain')
    filter$calculate(task)

    # information gain이 0.5보다 큰 경우
    keep <- names(which(filter$scores>0.5))
    task$select(keep)
    ```

### 5.3 Wrapper methods

모델의 성능을 최적화하는 feature들을 반복적으로 선택합니다. feature들에 순위를 매기는 대신, 일부 feature들만을 사용하여 학습한 뒤, 선택된 성능 지표에 따라 평가하게 됩니다.

#### 5.3.1. 간단한 예시

mlr3에서는 `FSelector`를 이용하여 위의 방법을 수행합니다.

```{r eval=FALSE}

library(mlr3fselect)
instance <- fselect(
  method='sequential',
  task= tsk('penguins'),
  learner = lrn('classif.rpart'),
  resampling = rsmp('holdout'),
  measures = msr('classif.acc')
)

```

성능 비교를 위한 feature들의 모든 subset을 확인하기 위해선 아래의 코드로 확인 가능합니다.

```{r eval=FALSE}
as.data.table(instance$archive) 
```

최적의 feature 들을 확인하기 위해서는

```{r eval=FALSE}
instance$result_feature_set
```

#### 5.3.2 FSelectInstance

#### 5.3.3. Fselector 클래스

`mlr3fselect::FSelector`에는 다양한 종류의 feature 선택 알고리즘이 존재합니다.

-   Random Search ([`mlr3fselect::FSelectorRandomSearch`](https://mlr3fselect.mlr-org.com/reference/mlr_fselectors_random_search.html))
-   Exhaustive Search ([`mlr3fselect::FSelectorExhaustiveSearch`](https://mlr3fselect.mlr-org.com/reference/mlr_fselectors_exhaustive_search.html))
-   Sequential Search ([`mlr3fselect::FSelectorSequential`](https://mlr3fselect.mlr-org.com/reference/mlr_fselectors_sequential.html))
-   Recursive Feature Elimination ([`mlr3fselect::FSelectorRFE`](https://mlr3fselect.mlr-org.com/reference/mlr_fselectors_rfe.html))
-   Design Points ([`mlr3fselect::FSelectorDesignPoints`](https://mlr3fselect.mlr-org.com/reference/mlr_fselectors_design_points.html))
-   Genetic Search ([`mlr3fselect::FSelectorGeneticSearch`](https://mlr3fselect.mlr-org.com/reference/mlr_fselectors_genetic_search.html))
-   Shadow Variable Search ([`mlr3fselect::FSelectorShadowVariableSearch`](https://mlr3fselect.mlr-org.com/reference/mlr_fselectors_shadow_variable_search.html))
