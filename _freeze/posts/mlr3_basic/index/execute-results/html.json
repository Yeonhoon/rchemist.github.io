{
  "hash": "ab01d71b419ea39695a6f1109029834a",
  "result": {
    "markdown": "---\ntitle: 'mlr3 기초'\ndescription: \"mlr3에 대한 소개 및 mlr3를 사용하기 위한 필수문법에 대해 소개합니다.\"\ndate: '2023-02-20'\ncategories: [mlr3, R, machine learning]\nimage: \"https://mlr3proba.mlr-org.com/logo.svg\"\n---\n\n\n# Introduction {#sec-introduction}\n\n`mlr3` (Machine Learning in R) 패키지와 생태계는 R 언어에서 분류 (classification), 회귀 (regression), 기타 머신러닝 작업들을 수행할 수 있도록 도와주는 포괄적, 객체 지향적, 확장 가능한 프레임워크입니다.\n\n`mlr3` 는 여러 머신러닝 알고리즘들을 통합하여 하나의 통일된 인터페이스로 제공함으로써 머신러닝 작업을 더 적절하게 수행할 수 있게끔 도와줍니다.\n\n`mlr3` 는 `R` 에 존재하는 `caret`, `tidymodels`, Python의 `scikit-learn`과 마찬가지로 더욱 유연한 머신러닝 플랫폼을 제공하는 것을 목표로 하고 있습니다.\n\nmlr3가 어떻게 작동하는지 빠르게 파악하고 싶으시다면, mlr3 [cheatsheets](https://cheatsheets.mlr-org.com/mlr3.pdf)을 살펴보시기 바랍니다.\n\n`mlr3verse`는 `mlr3`의 생태계로써, 머신러닝을 위한 R 패키지들의 집합체로 이루어져 있습니다. `mlr3` 패키지에서는 머신러닝을 위한 기본적인 코드들을 제공하고, 추가적인 학습 알고리즘, 파라미터 튜닝, 피처 선택 등은 확장 패키지들을 통해 이용할 수 있습니다.\n\n[![reference: mlr-org.com](https://raw.githubusercontent.com/mlr-org/mlr3/master/man/figures/mlr3verse.svg?sanitize=true){fig-align=\"center\"}](https://mlr-org.com/ecosystem.html)\n\n`mlr3` 생태계는 R의 `R6`와 `data.table`을 기반으로 만들어졌습니다. `R6`는 객체지향 (object orientation)을 위해, `data.table`은 데이터를 저장하고 작동시키기 위해 사용되었습니다.\n\n`mlr3`의 원활한 사용을 위해, 두 패키지의 기초를 살펴보도록 합시다.\n\n## R6\n\nR6는 객체지향 프로그래밍 (OOP)을 위한 R의 최근 패러다임 중 하나입니다. R6는 S3와 같이 R에 존재하던 기존의 객체지향성의 단점을 해결하는것이 특징입니다. 아마 다른 프로그래밍 언어에서 객체 지향 개념을 다루어 보셨다면, R6가 더 익숙하게 느껴질 것입니다.\n\nR6에서 객체(object)는 `R6Class()` 생성자 객체와 더불어 `$new()`메소드를 통해 생성됩니다.\n\n예를 들어 보겠습니다.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(R6)\nFoo = R6Class()\nfoo = Foo$new()\n```\n:::\n\n\n이 객체들은 자신들의 필드 안에서 변환 가능하도록 압축된 상태를 띄고 있는데, 우리는 이 객체들에 `$` 기호를 통해 접근할 수 있습니다.\n\n필드 뿐만 아니라, 객체들이 갖고 있는 메소드를 통해 각 객체의 상태를 파악하고 정보를 검색하거나, 객체의 내부 상태를 변경할 수 있습니다. 예를 들어 `mlr3` 의 학습모델(learner) 의 `$train()` 메소드를 통해, 모델을 학습된 상태로 변경할 수 있고, 이를 통해 예측을 할 수 있게 됩니다.\n\n::: callout-note\nR6 객체의 내부 요소는 다음과 같이 부릅니다.\n\n-   `$field`: 필드, 정보\n\n-   `$method()`: 메소드, 특정 동작 실행\n:::\n\nR6 객체들은 각각의 환경(environment)로서, 참조 특성 (reference semantics)을 갖습니다. 예를 들어, foo2 = foo 를 실행할 시, foo2 는 foo가 복사된 것은 아니지만, 하나의 객체를 참조하고 있는 것입니다. 따라서, `foo$bar = 3` 을 실행할 시, `foo2$bar` 역시 3이 됩니다.\n\n객체를 복사할 경우 `$clone()` 메소드와 `deep = TRUE` 인자를 사용해야 합니다.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfoo2 = foo$clone(deep=TRUE)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(mlr3verse)\n```\n:::\n\n\n::: callout-tip\nR6에 대해 더 자세히 알고 싶다면, R6 [vignettes](https://r6.r-lib.org/), 특히 [introduction](https://r6.r-lib.org/articles/Introduction.html)부분을 참고하세요. 포괄적인 R6의 정보를 얻고 싶다면, [Advanced R의 R6 챕터](https://adv-r.hadley.nz/r6.html)를 참고하세요.\n:::\n\n------------------------------------------------------------------------\n\n### `mlr3`의 필수 활용요소\n\n#### Sugar functions\n\n대부분의 `mlr3` 객체들은 sugar function으로 불리는 간편한 함수들을 제공합니다. 다시 말해, sugar function은 원래의 코드에 대한 단축키(shortcut)로서 사용자가 입력해야 하는 코드를 줄여줍니다. 예를 들어 `lrn(\"regr.rpart\")` 는 `LearnerRegrRpart$new()` 의 sugar 버전입니다.\n\n#### Dictionaries\n\n`mlr3`는 러너(`learners`)나 태스크(`tasks`) 객체들을 저장하기 위해 dictionary 구조를 사용합니다. dictionary 구조는 key와 value로 이루어져 있어 key와 value를 연관시켜주는데, 이는 실제 사전의 단어와 단어의 설명과 같다고 이해하시면 됩니다.\n\ndictionary는 연관된 객체들을 묶어 나열하고 검색하기 쉽게 하기 위해 사용됩니다. 예를 들어 특정 학습모델을 검색할 때, `mlr_learners` dictionary에 원하는 러너(key)를 입력하면 검색이 가능합니다.\n\n예를 들면 다음과 같습니다.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrequire(mlr3)\nmlr_learners$get('classif.rpart')\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n<LearnerClassifRpart:classif.rpart>: Classification Tree\n* Model: -\n* Parameters: xval=0\n* Packages: mlr3, rpart\n* Predict Types:  [response], prob\n* Feature Types: logical, integer, numeric, factor, ordered\n* Properties: importance, missings, multiclass, selected_features,\n  twoclass, weights\n```\n:::\n:::\n\n\n또한 `as.data.table(mlr3_learners)` 모든 학습 모델의 정보를 확인할 수도 있습니다.\n\n#### `mlr3viz`\n\n`mlr3viz`는 `mlr3` 생태계 안에서 시각화를 담당하는 패키지입니다. `ggplot2`의 `theme_minimal()`을 적용시킨 동일한 배경의 그래프들을 생성합니다. `mlr3viz`는 `ggplot2` 를 기반으로 하고 있으며, `fortify`와 `autoplot` 라는 확장 패키지를 통해 예측, 학습모델, 벤치마크 객체 등 `mlr3`의 결과물들을 시각화하는 데 사용됩니다. `mlr3viz`에서 가장 많이 사용되는 것은 `autoplot()`으로, 객체의 타입에 따라 그래프의 출력 결과가 결정됩니다.\n\n------------------------------------------------------------------------\n\n# Basics {#sec-basics}\n\n## Tasks\n\n태스크(task)은 데이터와 머신러닝 문제들을 정의한 메타데이터를 갖고 있는 객체입니다. 예를 들면 머신러닝의 분류에서 타겟 피처의 이름이 메타 데이터 입니다.\n\n한마디로, 태스크는 우리가 활용하는 기본 데이터와 머신러닝을 위해 필요한 데이터들을 담아둔 정보 등이 포함된 객체입니다.\n\n이 메타 데이터는 사용자가 모덜이 학습될 때 예측 타겟을 다시 지정해줄 필요 없도록 태스크와 함께 작동하게 됩니다.\n\n::: callout-note\nTask와 Learner 등 영어로 지정된 단어들은 따로 번역하지 않고, 소리 그대로 **\"태스크\"**와 **\"러너\"**로 부르겠습니다.\n:::\n\n### 내장 태스크\n\n`mlr3`에는 `mlr_tasks`라고 하는 R6 Dictionary 를 통해 미리 지정된 머신러닝 태스크를 제공하고 있습니다.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmlr_tasks\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n<DictionaryTask> with 19 stored values\nKeys: bike_sharing, boston_housing, breast_cancer, german_credit, ilpd,\n  iris, kc_housing, moneyball, mtcars, optdigits, penguins,\n  penguins_simple, pima, sonar, spam, titanic, usarrests, wine, zoo\n```\n:::\n:::\n\n\n`mlr_tasks`에 내장된 태스크를 가져오기 위해선, `tsk()` 함수와 불러오고자 하는 태스크의 이름을 입력하면 됩니다.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntask_mtcars <- tsk(\"mtcars\")\ntask_mtcars\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n<TaskRegr:mtcars> (32 x 11): Motor Trends\n* Target: mpg\n* Properties: -\n* Features (10):\n  - dbl (10): am, carb, cyl, disp, drat, gear, hp, qsec, vs, wt\n```\n:::\n:::\n\n\n특정 태스크에 대해 보다 많은 정보가 필요하다면, `help()`메소드를 이용하시면 됩니다.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntask_mtcars$help()\n```\n:::\n\n\n::: callout-tip\nR을 사용하셨던 분들이라면 위와 같은 구조의 코드가 낯설 것입니다. 보통 도움말을 보기 위해선 `help()`나 `?`를 이용했을테니까요.\n\n`task_mtcars$help()` 와 같은 구조가 바로 `R6` 객체 구조입니다. [Introduction](#sec-introduction)에서 간단히 소개했었죠? 앞으로 `mlr3`를 배우며, 계속 사용하게 될 것입니다.\n:::\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntask_sonar <- tsk('sonar')\nsplit <- partition(task_sonar, ratio=.7)\n```\n:::\n\n\n### 외부 데이터 태스크로 변환\n\n`mlr3`에서 제공하는 데이터가 아닌, 외부의 데이터셋을 `mlr3` 패키지와 사용하려면 아래와 같이 데이터셋을 태스크로 변환해야 합니다. 예를 들어, `survival` 패키지의 lung 데이터셋을 `mlr3`의 태스크 객체로 변환한다면, 아래와 같이 진행할 수 있습니다.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(survival)\nlibrary(data.table)\ntask_lung = as_task_classif(\n  as.data.table(lung)[,.(age, sex, wt.loss, ph.ecog,status)],\n             target = \"status\",\n  \n             id = \"lung\")\ntask_lung\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n<TaskClassif:lung> (228 x 5)\n* Target: status\n* Properties: twoclass\n* Features (4):\n  - dbl (4): age, ph.ecog, sex, wt.loss\n```\n:::\n:::\n\n\n::: callout-tip\n태스크 생성자인 `as_task_regr()`과 `as_task_classif()`는 각각 머신러닝의 회귀와 분류를 수행하기 위한 태스크를 만드는 함수입니다.\n\n외부의 데이터를 태스크로 변환할 때, [UTF8 이름](https://en.wikipedia.org/wiki/UTF-8)을 따르지 않는 경우, 머신러닝 학습과정에서 오류가 발생합니다. 예를 들면,\n\n    Task 'lung' has missing values in column(s) 'ph.ecog', 'wt.loss', but learner 'classif.ranger' does not support this\n\n따라서 `make.names()` 함수를 이용해 데이터의 열 이름을 변경하는 것을 권장합니다.\n:::\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(mlr3viz)\nautoplot(task_lung, type = \"pairs\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-10-1.png){width=672}\n:::\n:::\n\n\n### 데이터 살펴보기\n\n태스크 객체는 테이블 형태의 데이터와 함께, 메타 데이터를 포함하고 있습니다. 예를 들면 행과 열의 개수, 피처(feature) 변수, 타겟 변수와 각 변수의 데이터유형 등을 확인할 수 있습니다.\n\n이런 메타 데이터들은 field를 통해 확인이 가능합니다.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntask_lung$nrow\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 228\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ntask_lung$ncol\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 5\n```\n:::\n:::\n\n\n피처와 타겟변수의 이름은 각각 `$feature_names` 와 `$target_names` 에 저장되어 있습니다. 여기서 `target` 은 머신러닝을 통해 예측하고자 하는 변수를 의미합니다.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntask_lung$feature_names\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"age\"     \"ph.ecog\" \"sex\"     \"wt.loss\"\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ntask_lung$target_names\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"status\"\n```\n:::\n:::\n\n\n한편 태스크 안에 들어있는 데이터는 `data.table` 객체로, `$data()` 메소드를 통해 확인할 수 있습니다.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntask_lung$data()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n     status age ph.ecog sex wt.loss\n  1:      2  74       1   1      NA\n  2:      2  68       0   1      15\n  3:      1  56       0   1      15\n  4:      2  57       1   1      11\n  5:      2  60       0   1       0\n ---                               \n224:      1  77       1   1       3\n225:      1  39       0   1      -5\n226:      1  75       2   2       5\n227:      1  66       1   1       1\n228:      1  58       1   2       0\n```\n:::\n:::\n\n\n`$data()` 메소드 안에서 rows와 cols를 통해 원하는 데이터를 확인할 수 있습니다.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntask_lung$data(rows=1:10, cols=\"status\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n    status\n 1:      2\n 2:      2\n 3:      1\n 4:      2\n 5:      2\n 6:      1\n 7:      2\n 8:      2\n 9:      2\n10:      2\n```\n:::\n:::\n\n\n태스크를 `data.table` 객체로 바꾼다면, 데이터에 있는 모든 변수를 확인할 수도 있습니다.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsummary(as.data.table(task_lung))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n status       age           ph.ecog            sex           wt.loss       \n 1: 63   Min.   :39.00   Min.   :0.0000   Min.   :1.000   Min.   :-24.000  \n 2:165   1st Qu.:56.00   1st Qu.:0.0000   1st Qu.:1.000   1st Qu.:  0.000  \n         Median :63.00   Median :1.0000   Median :1.000   Median :  7.000  \n         Mean   :62.45   Mean   :0.9515   Mean   :1.395   Mean   :  9.832  \n         3rd Qu.:69.00   3rd Qu.:1.0000   3rd Qu.:2.000   3rd Qu.: 15.750  \n         Max.   :82.00   Max.   :3.0000   Max.   :2.000   Max.   : 68.000  \n                         NA's   :1                        NA's   :14       \n```\n:::\n:::\n\n\n### 태스크 변환자(Mutators)\n\n머신러닝을 수행하며, 행과 열들을 선택하는 경우가 종종 있습니다. 예를 들면 train-test split을 위해 행을 선택하는 경우, 모델링에 넣을 피처들을 선택하는 경우가 있겠죠.\n\n`mlr3`의 태스크는 행을 선택하는 `$filter()`, 열을 선택하는 `$select()` 를 이용해 원하는 조건의 데이터를 추출할 수 있습니다.\n\n한 가지 주의해야 할 것이 있습니다. \\$select()와 \\$filter()는 변환자이기 때문에, 기존의 태스크를 수정하게 됩니다. 다시 말해, 처음에 있던 원래 데이터를 바꿔버리는 것이죠.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntask_iris <- tsk(\"iris\")\ntask_iris$select(c(\"Sepal.Length\",\"Petal.Width\"))\ntask_iris$filter(2:4)\ntask_iris$data()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n   Species Petal.Width Sepal.Length\n1:  setosa         0.2          4.9\n2:  setosa         0.2          4.7\n3:  setosa         0.2          4.6\n```\n:::\n:::\n\n\n이를 방지하기 위해서는 `$clone()` 메소드를 이용해 새로운 태스크로 복사한 뒤에 행이나 열을 선택하는 작업하시면 됩니다.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntask_iris_copy <- task_iris$clone()\ntask_iris_copy$filter(2)\ntask_iris_copy$data()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n   Species Petal.Width Sepal.Length\n1:  setosa         0.2          4.9\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ntask_iris$data()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n   Species Petal.Width Sepal.Length\n1:  setosa         0.2          4.9\n2:  setosa         0.2          4.7\n3:  setosa         0.2          4.6\n```\n:::\n:::\n\n\n`task_iris_copy`는 `task_iris`를 복사한 뒤, 2번째 행을 `$filter()` 했지만, `task_iris`의 데이터는 아무 변화가 없는 것을 확인할 수 있습니다.\n\n## Learner\n\n러너는 클래스는 널리 알려진 많은 머신러닝 패키지들을 통일된 형태로 제공합니다. 태스크와 마찬가지로 `mlr_learners` dictionary를 통해 확인할 수 있습니다.\n\n러너는 머신러닝 모델을 학습(train)하고 예측하는 역할을 수행합니다. 태스크에서는 외부 데이터도 태스크로 만들 수 있었던 것과 달리, 러너는 `mlr3`에서 지원하는 것만 사용할 수 있습니다. mlr3에서 제공하는 러너들은 다음과 같습니다.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nas.data.table(mlr_learners) |> head()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n                   key                              label task_type\n1:   classif.cv_glmnet                               <NA>   classif\n2:       classif.debug   Debug Learner for Classification   classif\n3: classif.featureless Featureless Classification Learner   classif\n4:      classif.glmnet                               <NA>   classif\n5:        classif.kknn                               <NA>   classif\n6:         classif.lda                               <NA>   classif\n                                          feature_types\n1:                              logical,integer,numeric\n2:     logical,integer,numeric,character,factor,ordered\n3: logical,integer,numeric,character,factor,ordered,...\n4:                              logical,integer,numeric\n5:               logical,integer,numeric,factor,ordered\n6:               logical,integer,numeric,factor,ordered\n                   packages\n1: mlr3,mlr3learners,glmnet\n2:                     mlr3\n3:                     mlr3\n4: mlr3,mlr3learners,glmnet\n5:   mlr3,mlr3learners,kknn\n6:   mlr3,mlr3learners,MASS\n                                                              properties\n1:                         multiclass,selected_features,twoclass,weights\n2:                         hotstart_forward,missings,multiclass,twoclass\n3: featureless,importance,missings,multiclass,selected_features,twoclass\n4:                                           multiclass,twoclass,weights\n5:                                                   multiclass,twoclass\n6:                                           multiclass,twoclass,weights\n   predict_types\n1: response,prob\n2: response,prob\n3: response,prob\n4: response,prob\n5: response,prob\n6: response,prob\n```\n:::\n:::\n\n\n러너의 기본 형태는 Learner입니다. Learner로 시작하는 다양한 러너들이 존재합니다. `mlr3`의 러너들은 [`mlr3learners`](https://mlr3learners.mlr-org.com/)와 [`mlr3extralearners`](https://mlr3extralearners.mlr-org.com/)패키지를 통해 확인 가능합니다.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmlr3learners::LearnerClassifLogReg\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n<LearnerClassifLogReg> object generator\n  Inherits from: <LearnerClassif>\n  Public:\n    initialize: function () \n    loglik: function () \n    clone: function (deep = FALSE) \n  Private:\n    .train: function (task) \n    .predict: function (task) \n  Parent env: <environment: namespace:mlr3learners>\n  Locked objects: TRUE\n  Locked class: FALSE\n  Portable: TRUE\n```\n:::\n:::\n\n\n러너의 sugar function은 `lrn()` 입니다.\n\n::: callout-caution\nmlr3의 러너를 실행하기 위한 패키지가 없다면 아래와 같은 경고 메시지가 뜹니다.\n\n    Warning: Package 'ranger' required but not installed for Learner 'classif.ranger\n\n패키지를 설치해주시면 간단히 해결됩니다.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ninstall.packages(\"ranger\")\n```\n:::\n\n:::\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlearner_rf <- lrn('classif.ranger', predict_type='prob')\nlearner_rf\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n<LearnerClassifRanger:classif.ranger>\n* Model: -\n* Parameters: num.threads=1\n* Packages: mlr3, mlr3learners, ranger\n* Predict Types:  response, [prob]\n* Feature Types: logical, integer, numeric, character, factor, ordered\n* Properties: hotstart_backward, importance, multiclass, oob_error,\n  twoclass, weights\n```\n:::\n:::\n\n\n각 러너들은 아래의 메타데이터를 갖고 있습니다.\n\n-   `$feature_types`: 피처들의 유형\n\n-   `$packages`: 모델을 학습시키고 예측하기 위해 필요한 패키지들\n\n-   `$properties`: 해당 러너가 갖고 있는 추가적인 특성. 예를 들어 importance 특성이 있다면 학습 후, 각 피처들의 importance를 추출할 수 있습니다.\n\n-   `$predict_types`: 해당 러너를 활용해 가능한 예측 유형입니다. 분류 유형의 러너는 response와 prob을 출력합니다.\n\n모든 러너들은 두 단계에 걸쳐 진행됩니다.\n\n-   학습 (Training): `$train()` 메소드를 통해 학습시키고자 하는 태스크를 전달합니다.\n\n-   예측 (Prediction): `$predict()` 메소드에 학습 때 사용하지 않은 데이터를 사용합니다. 학습 데이터를 기반으로 훈련된 모델이 새로운 데이터를 받아 예측값을 반환합니다.\n\n::: callout-warning\n러너가 학습되지 않았다면 `$predict()` 실행 시 에러가 발생합니다.\n:::\n\n### train: 학습시키기\n\n앞서 말했듯이, `mlr3`에서는 러너에 태스크를 투입하여 모델을 학습시킵니다. 머신러닝에서는 태스크를 투입하기 전, 훈련에 사용할 데이터와 예측에 사용할 데이터를 나누는 것이 일반적입니다.\n\n`mlr3` 에서는 `$partition()` 메소드를 이용해 두 개의 데이터로 나눌 수 있습니다. 기본값은 전체 데이터의 67%를 훈련에, 나머지 33%를 예측에 사용합니다. 물론 이 비율은 ratio 인자 (범위: 0\\~1)를 통해 변경 가능합니다.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntask_breast <- tsk(\"breast_cancer\")\nsplits <- partition(task_breast, ratio = 0.7)\n```\n:::\n\n\n데이터를 나눠줬으니, 이제 모델을 학습시켜보도록 하겠습니다. 위에서 선언한 랜덤포레스트 러너에서 `$train()` 메소드를 실행시킵니다. 태스크와 `row_ids`에는 split 중 `train`에 해당하는 부분을 입력합니다.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlearner_rf$train(task_breast, \n                 row_ids = split$train)\nlearner_rf$model\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nRanger result\n\nCall:\n ranger::ranger(dependent.variable.name = task$target_names, data = task$data(),      probability = self$predict_type == \"prob\", case.weights = task$weights$weight,      num.threads = 1L) \n\nType:                             Probability estimation \nNumber of trees:                  500 \nSample size:                      146 \nNumber of independent variables:  9 \nMtry:                             3 \nTarget node size:                 10 \nVariable importance mode:         none \nSplitrule:                        gini \nOOB prediction error (Brier s.):  0.03939987 \n```\n:::\n:::\n\n\n학습을 시킨 이후, \\$model 필드를 통해 학습된 결과를 확인할 수 있습니다. 어떤 하이퍼파라미터가 사용되었는지 등의 정보를 확인할 수 있습니다.\n\n각 러너들은 하이퍼파라미터들을 조정해줄 수 있습니다. 러너들의 파라미터를 확인하는 명령어는 다음과 같습니다.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlearner_rf$param_set\n```\n:::\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n```\n                       id    class lower upper\n1:                  alpha ParamDbl  -Inf   Inf\n2: always.split.variables ParamUty    NA    NA\n3:          class.weights ParamUty    NA    NA\n4:                holdout ParamLgl    NA    NA\n5:             importance ParamFct    NA    NA\n6:             keep.inbag ParamLgl    NA    NA\n                                         levels nlevels is_bounded special_vals\n1:                                                  Inf      FALSE    <list[0]>\n2:                                                  Inf      FALSE    <list[0]>\n3:                                                  Inf      FALSE    <list[0]>\n4:                                   TRUE,FALSE       2       TRUE    <list[0]>\n5: none,impurity,impurity_corrected,permutation       4       TRUE    <list[0]>\n6:                                   TRUE,FALSE       2       TRUE    <list[0]>\n          default storage_type  tags\n1:            0.5      numeric train\n2: <NoDefault[3]>         list train\n3:                        list train\n4:          FALSE      logical train\n5: <NoDefault[3]>    character train\n6:          FALSE      logical train\n```\n:::\n:::\n\n\n현재 학습에 사용된 하이퍼 파라미터들은 values 필드에 저장되어있습니다.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlearner_rf$param_set$values\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n$num.threads\n[1] 1\n```\n:::\n:::\n\n\n위와 같이 하이퍼 파라미터에 접근한 뒤, 기존의 값을 원하는 값으로 변경하거나, 새로운 하이퍼파라미터에 값을 설정해줄 수 있습니다.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlearner_rf$param_set$values$num.threads = 10\nlearner_rf$param_set$values$num.trees = 20\nlearner_rf$param_set$values\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n$num.threads\n[1] 10\n\n$num.trees\n[1] 20\n```\n:::\n:::\n\n\n또는 `lrn()` 함수로 러너를 생성할 때, 원하는 하이퍼파라미터를 설정해줄 수 있습니다.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlearner_rf <- lrn('classif.ranger', num.trees= 30)\nlearner_rf$param_set$values\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n$num.threads\n[1] 1\n\n$num.trees\n[1] 30\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nlearner_rf$train(task_breast, row_ids = split$train)\nlearner_rf\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n<LearnerClassifRanger:classif.ranger>\n* Model: ranger\n* Parameters: num.threads=1, num.trees=30\n* Packages: mlr3, mlr3learners, ranger\n* Predict Types:  [response], prob\n* Feature Types: logical, integer, numeric, character, factor, ordered\n* Properties: hotstart_backward, importance, multiclass, oob_error,\n  twoclass, weights\n```\n:::\n:::\n\n\n변경된 파라미터가 적용된 것을 확인할 수 있습니다.\n\n::: callout-note\n하이퍼 파라미터에 대한 자세한 설명은 하이퍼파라미터 튜닝에서 더 자세히 다루도록 하겠습니다.\n:::\n\n### predict: 예측하기\n\n모델 학습이 완료되었다면, 예측값을 만들어볼 수 있습니다. split의 test 를 이용해 `$predict()` 메소드를 실행합니다.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nprediction <- learner_rf$predict(task_breast, \n                                 row_ids = split$test)\nprediction\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n<PredictionClassif> for 62 observations:\n    row_ids     truth  response\n          5    benign    benign\n          6 malignant malignant\n          8    benign    benign\n---                            \n        195 malignant malignant\n        196 malignant malignant\n        198    benign    benign\n```\n:::\n:::\n\n\n예측값을 살펴보니, 예측값이 범주로 나타났습니다. 만약 범주에 대한 예측 확률값을 구하고 싶을 경우, `lrn()`의 `predict_type`을 `prob`으로 조정해주면 됩니다.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlearner_rf <- lrn(\"classif.ranger\", \n                  predict_type=\"prob\")\nlearner_rf$train(task_breast, \n                 row_ids = split$train)\nprediction <- learner_rf$predict(task_breast, \n                                 row_ids = split$test)\nprediction\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n<PredictionClassif> for 62 observations:\n    row_ids     truth  response prob.malignant prob.benign\n          5    benign    benign    0.095203968 0.904796032\n          6 malignant malignant    0.992784921 0.007215079\n          8    benign    benign    0.001666667 0.998333333\n---                                                       \n        195 malignant malignant    0.967087302 0.032912698\n        196 malignant malignant    0.935711905 0.064288095\n        198    benign    benign    0.000000000 1.000000000\n```\n:::\n:::\n\n\nprediction 객체에서는 `$confusion` 을 이용해 confusion matrix를 확인할 수 있습니다.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nprediction$confusion\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n           truth\nresponse    malignant benign\n  malignant        30      0\n  benign            0     32\n```\n:::\n:::\n\n\n우리가 만든 모델이 내놓은 예측값에 대한 시각화를 진행해줄 수 있습니다. `mlr3viz` 패키지의 `autoplot()` 기능을 이용해주면 됩니다.\n\n`autoplot()`에서 type을 어떻게 지정해주는지에 따라 예측값에 시각화가 다르게 나타납니다.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(mlr3viz)\nautoplot(prediction)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-36-1.png){width=672}\n:::\n:::\n\n\n위의 그림은 test 데이터의 실제 target 값과 머신러닝 모델이 예측한 target을 비교한 값입니다.\n\n그 외에도 분류 계열의 모델에는 AUROC(`type=\"roc\"` )와 AUPRC(`type=\"prc\"`) 등을 시각화할 수 있습니다.\n\n\n::: {.cell layout=\"[[45,-10,45]]\" output-location='fragment'}\n\n```{.r .cell-code}\n# install.packages(\"precrec\")\nautoplot(prediction, type=\"roc\")\n```\n\n::: {.cell-output-display}\n![AUROC](index_files/figure-html/unnamed-chunk-37-1.png){width=672}\n:::\n\n```{.r .cell-code}\nautoplot(prediction, type=\"prc\")\n```\n\n::: {.cell-output-display}\n![AUPRC](index_files/figure-html/unnamed-chunk-37-2.png){width=672}\n:::\n:::\n\n\n### Evaluation: 성능 평가\n\n성능 평가는 머신러닝 모델링 과정에서 중요한 단계입니다. 앞서 예측 부분에서 예측값을 시각화로 표현했습니다. 그와 더불에 `mlr3`에서는 `msr()` 함수를 이용해 다양한 성능 지표들을 계산하고 비교할 수 있습니다. `mlr_measures` 딕셔너리를 보면 계산 가능한 지표들이 나와있습니다.\n\n예를 들어, 분류(classification) 모델에 대한 지표들을 살펴보면 다음과 같습니다.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmlr_measures$keys(\"classif\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n [1] \"classif.acc\"         \"classif.auc\"         \"classif.bacc\"       \n [4] \"classif.bbrier\"      \"classif.ce\"          \"classif.costs\"      \n [7] \"classif.dor\"         \"classif.fbeta\"       \"classif.fdr\"        \n[10] \"classif.fn\"          \"classif.fnr\"         \"classif.fomr\"       \n[13] \"classif.fp\"          \"classif.fpr\"         \"classif.logloss\"    \n[16] \"classif.mauc_au1p\"   \"classif.mauc_au1u\"   \"classif.mauc_aunp\"  \n[19] \"classif.mauc_aunu\"   \"classif.mbrier\"      \"classif.mcc\"        \n[22] \"classif.npv\"         \"classif.ppv\"         \"classif.prauc\"      \n[25] \"classif.precision\"   \"classif.recall\"      \"classif.sensitivity\"\n[28] \"classif.specificity\" \"classif.tn\"          \"classif.tnr\"        \n[31] \"classif.tp\"          \"classif.tpr\"        \n```\n:::\n:::\n\n\n모델의 성능을 계산하기 위한 지표는 한 가지만 사용할 수 있고, 여러 가지를 사용할수도 있습니다.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmeasure <- msr(\"classif.auc\")\nmeasures <- msrs(c(\"classif.auc\",\"classif.auc\"))\n```\n:::\n\n\n모든 성능 지표들은 예측값과 test 데이터의 실제 값의 차이를 통해 수치화된 값입니다. 이 말은 모델의 성능을 평가하기 위해선, 예측값을 비교하기 위한, 모델 학습에 사용되지 않은 실제값이 필요하다는 것입니다.\n\n이제, `Measure` 객체 중 하나인 `classif.acc`를 통해 위에서 만든 랜덤포레스트 모델의 성능을 평가해보도록 하겠습니다. 지표(measure)를 생성한 뒤, 모델의 예측값 객체(prediction)의 `$score()` 메소드에 넘겨주면 해당 지표의 성능이 평가됩니다.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmeasure <- msr(\"classif.acc\")\nmeasure\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n<MeasureClassifSimple:classif.acc>: Classification Accuracy\n* Packages: mlr3, mlr3measures\n* Range: [0, 1]\n* Minimize: FALSE\n* Average: macro\n* Parameters: list()\n* Properties: -\n* Predict type: response\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nprediction$score(measure)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nclassif.acc \n          1 \n```\n:::\n:::\n\n\n::: callout-note\n`$score()`는 measure 없이 사용될 수 있습니다. 이럴 경우, 분류의 경우 기본값인 분류오차(`classif.ce`)가, 회귀는 평균제곱오차(`regr.mse`)가 적용됩니다.\n:::\n\n`$score()`를 이용해 여러 종류의 성능 지표를 한 번에 계산하는 것도 가능합니다. 예를 들어, 민감도(`classif.sensitivity`)와 특이도(`classif.specificity`)를 한번에 계산할 경우,\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmeasures <- msrs(c(\"classif.sensitivity\",\"classif.specificity\"))\n\nprediction$score(measures)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nclassif.sensitivity classif.specificity \n                  1                   1 \n```\n:::\n:::\n\n\n뿐만 아니라, `mlr3`에서는 예측 모델의 품질을 정량화하는 지표로도 모델을 평가할 수 있습니다. 예를 들어, 학습하는 시간과 예측하는 시간을 평가하기 위해선\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmeasures <- msrs(c(\"time_train\", \"time_predict\"))\nprediction$score(measures,learner = learner_rf)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n  time_train time_predict \n        0.01         0.01 \n```\n:::\n:::\n\n\n참고로, 위처럼 학습시간과 예측 시간을 평가하기 위해선 학습된 러너를 `$score()`에 입력해주어야 합니다.\n\n한편, 일부 지표들은 스스로 하이퍼파라미터를 가지고 있습니다. 대표적인 예로 `selected_features` 지표가 있습니다. 이 지표는 \"selected_features\" 속성이 있는 러너에만 사용 가능한 지표로서, 모델이 학습 시 사용한 피처에 대한 정보를 제공해줍니다. 이런 지표의 경우, `$score()` 에 태스크와 러너를 추가로 입력해주어야 합니다.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntask_boston <- tsk(\"boston_housing\")\nsplits <- partition(task_boston)\nlearner_rpart <- lrn(\"regr.rpart\")\n\nlearner_rpart$train(task_boston, splits$train)\nprediction <- learner_rpart$predict(task_boston, splits$test)\nmeasure <- msr(\"selected_features\")\nprediction$score(measure, task = task_boston, learner = learner_rpart)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nselected_features \n                1 \n```\n:::\n:::\n\n\nselected_features 는 선택된 피처의 수를 정규화해줄 수 있는 하이퍼파라미터를 설정할 수 있습니다.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmeasure <- msr(\"selected_features\", normalize=T)\nprediction$score(measure, task=task_boston, learner = learner_rpart)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nselected_features \n       0.05555556 \n```\n:::\n:::\n\n\n------------------------------------------------------------------------\n\n## 레퍼런스\n\n-   <https://mlr3.mlr-org.com/>\n\n-   <https://mlr3book.mlr-org.com/basics.html>\n",
    "supporting": [
      "index_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}